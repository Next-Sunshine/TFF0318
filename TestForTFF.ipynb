{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestForTFF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1xpcHa/ag7AWQZAwAIdaa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TFF0318/blob/master/TestForTFF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9pTTi0lPh1w",
        "colab_type": "code",
        "outputId": "2d1ed963-67e3-44a4-f61d-9ede6006d2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "#环境测试\n",
        "#@test {\"skip\":true}\n",
        "!pip install --quiet --upgrade tensorflow_federated\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 3.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 43.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 35.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 36.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 30kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 249kB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 30.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 35.8MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITkxSUMiRa01",
        "colab_type": "code",
        "outputId": "2b2fe26a-41a9-42da-efc1-cfec7c839d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, world!')()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello, world!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRJgOTiAR3T4",
        "colab_type": "code",
        "outputId": "e3bbc7cb-aa91-4dde-e963-7a27dce7b261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#装载数据集，实验使用EMNIST数据集\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
        "class MNISTLoader():\n",
        "    def __init__(self):\n",
        "        #emnist = tff.simulation.datasets.emnist\n",
        "        (self.train_data, self.train_label), (self.test_data, self.test_label) = emnist_train, emnist_test\n",
        "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
        "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
        "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
        "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
        "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
        "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
        " \n",
        "    def get_batch(self, batch_size):\n",
        "        # 从数据集中随机取出batch_size个元素并返回\n",
        "        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
        "        return self.train_data[index, :], self.train_label[index]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist_digitsonly.tar.bz2\n",
            "97402880/97398400 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHXBNT_UxIWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#此处得到客户端的总数K，因为每一轮随机选择C×K的向上取整\n",
        "#根据FedAvg做的研究C取0.2可获得较好的性能，为了简化模型K这里取固定的数\n",
        "K = len(emnist_train.client_ids)\n",
        "C = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc578aa2UuZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NUM_CLIENTS在实验的时候应该是K×C\n",
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "#预处理，将图片中的‘pixels'、‘label'分别表示成x和y\n",
        "#将28×28的图像展平成784个元素，打乱顺序\n",
        "def preprocess(dataset):\n",
        "  #内部函数将像素和标签转换成x和y，并将像素展平\n",
        "  def batch_format_fn(element):\n",
        "    return collections.OrderedDict(\n",
        "        x = tf.reshape(element['pixels'], [-1,28,28,1]),\n",
        "        #x = np.expand_dims(element['pixels'], axis=-1),\n",
        "        #x = element['pixels'],\n",
        "        y = tf.reshape(element['label'], [-1,1])\n",
        "    )\n",
        "  \n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRqmbbzamP1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#为指定用户创建联邦数据,接收训练集和用户id\n",
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "    ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDHJSC8OYaZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#这里改成随机获得NUM_CLIENTS个用户，模拟联邦学习每轮的随机选择用户\n",
        " sample_clients = random.sample(emnist_train.client_ids, NUM_CLIENTS)\n",
        "# sample_clients #说明随机用户的id是取出来了的\n",
        "# type(emnist_train.client_ids)  #client_ids是一个列表\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZEcia5FltoP",
        "colab_type": "text"
      },
      "source": [
        "间隔界"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4MRt7FEh2gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#！自己添加代码中，正在想办法把训练模型改成CNN\n",
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            filters=32,             # 卷积层神经元（卷积核）数目\n",
        "            kernel_size=[5, 5],     # 感受野大小\n",
        "            padding='same',         # padding策略（vaild 或 same）\n",
        "            activation=tf.nn.relu   # 激活函数\n",
        "        )\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=[5, 5],\n",
        "            padding='same',\n",
        "            activation=tf.nn.relu\n",
        "        )\n",
        "        #print(\"kernel:\",kernel_size)\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n",
        "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        " \n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)                  # [batch_size, 28, 28, 32]\n",
        "        x = self.pool1(x)                       # [batch_size, 14, 14, 32]\n",
        "        x = self.conv2(x)                       # [batch_size, 14, 14, 64]\n",
        "        x = self.pool2(x)                       # [batch_size, 7, 7, 64]\n",
        "        x = self.flatten(x)                     # [batch_size, 7 * 7 * 64]\n",
        "        x = self.dense1(x)                      # [batch_size, 1024]\n",
        "        x = self.dense2(x)\n",
        "        #tf.nn.softmax()将原始输出归一化，且能凸显原始向量中最大的值                      # [batch_size, 10]\n",
        "        output = tf.nn.softmax(x)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRwWOrazj5R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#！此处也是自己添加代码\n",
        "num_epochs = 5\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "#实例化模型\n",
        "model = CNN()\n",
        "#data_loader = MNISTLoader()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw419GpLlmz9",
        "colab_type": "text"
      },
      "source": [
        "间隔界\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNo6O_5qSNSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "213d978f-f32b-4839-e6c8-815a857c3dba"
      },
      "source": [
        "#创建一个变量集合来表示所有变量,包括model(weights+bias)以及metrics(num_examples,loss_sum,accuracy_sum)\n",
        "# MnistVariables = collections.namedtuple(\n",
        "#     'MnistVariables','weights bias num_examples loss_sum accuracy_sum'\n",
        "# )\n",
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables','conv_kernel pool_kernel num_examples loss_sum accuracy_sum'\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSEDLYxJTZ8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#创建变量并初始化\n",
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      # weights=tf.Variable(\n",
        "      #     # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),\n",
        "      #     lambda: tf.zeros(dtype=tf.float32, shape=(28,28,10)),\n",
        "      #     name='weights',\n",
        "      #     trainable=True),\n",
        "      # bias=tf.Variable(\n",
        "      #     lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
        "      #     name='bias',\n",
        "      #     trainable=True),\n",
        "      kernel=tf.Variable(\n",
        "          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(5,5)),\n",
        "          name='conv_kernel',\n",
        "          trainable=True),\n",
        "      kernel=tf.Variable(\n",
        "          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(2,2)),\n",
        "          name='pool_kernel',\n",
        "          trainable=True),\n",
        "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib6kQLwtUh5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#自定义前向传播函数\n",
        "def mnist_forward_pass(variables, batch):\n",
        "  X = batch['x']  #取训练图片以及\n",
        "  print(str(X)) #形状是[None, 784]，为什么预处理没有生效\n",
        "  y = batch['y'] #取标签\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(X)\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    #print(\"loss %f\" % loss)\n",
        "  grads = tape.gradient(loss, model.variables)\n",
        "  optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "  predictions = tf.cast(tf.argmax(y_pred,1), tf.int32)\n",
        "  '''\n",
        "  #！后面为原版代码\n",
        "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
        "  predictions = tf.cast(tf.argmax(y,1), tf.int32) \n",
        "\n",
        "  flat_labels = tf.reshape(batch['y'], [-1])\n",
        "  #计算交叉熵损失\n",
        "  loss = -tf.reduce_mean(\n",
        "      tf.reduce_sum(tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))\n",
        "  '''\n",
        "  #计算准确率\n",
        "  flat_labels = tf.reshape(batch['y'], [-1])\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
        "  \n",
        "  #样本数\n",
        "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
        "\n",
        "  #更新样本数、损失和、精度和,每一批都考虑了自己的权重\n",
        "  variables.num_examples.assign_add(num_examples)\n",
        "  variables.loss_sum.assign_add(loss * num_examples)\n",
        "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mcpE0twbxz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#计算本地用户的metrics度量\n",
        "def get_local_mnist_metrics(variables):\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=variables.num_examples,\n",
        "      loss=variables.loss_sum / variables.num_examples,\n",
        "      accuracy=variables.accuracy_sum / variables.num_examples\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv_a5zrVch3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#集合每个设备发出的本地度量\n",
        "@tff.federated_computation\n",
        "def aggregate_mnist_metrics_across_clients(metrics):\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=tff.federated_sum(metrics.num_examples),\n",
        "      loss=tff.federated_mean(metrics.loss, metrics.num_examples),\n",
        "      accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE3FpcO5dNr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#自定义模型，创建tff.learning.model实例\n",
        "class MnistModel(tff.learning.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  #所有的“tf.Variables”都应该在“__init__”中引入\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    #return [self._variables.weights, self._variables.bias]\n",
        "    return [self._variables.conv_kernel, self._variables.pool_kernel]\n",
        "  \n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "  \n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [self._variables.num_examples, self._variables.loss_sum,\n",
        "         self._variables.accuracy_sum]\n",
        "  \n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict(\n",
        "        # x=tf.TensorSpec([None, 784], tf.float32),\n",
        "        x=tf.TensorSpec([None, 28,28,1], tf.float32),\n",
        "        y=tf.TensorSpec([None, 1], tf.int32)\n",
        "    )\n",
        "\n",
        "  @tf.function\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    #取出样本数\n",
        "    num_examples = tf.shape(batch['x'])[0]\n",
        "    return tff.learning.BatchOutput(\n",
        "        loss=loss, predictions=predictions, num_examples=num_examples)\n",
        "    \n",
        "  @tf.function\n",
        "  def report_local_outputs(self):\n",
        "    return get_local_mnist_metrics(self._variables)\n",
        "  \n",
        "  @property\n",
        "  def federated_output_computation(self):\n",
        "    return aggregate_mnist_metrics_across_clients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfqC79A4hVfw",
        "colab_type": "code",
        "outputId": "f331330b-0b0e-4536-f003-3b34421822f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "#创建迭代器执行联合平均的迭代过程\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    MnistModel,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"batch:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7fb2a98ec840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7fb2a98ec840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9ebb9613346f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m iterative_process = tff.learning.build_federated_averaging_process(\n\u001b[1;32m      2\u001b[0m     \u001b[0mMnistModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclient_optimizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/federated_averaging.py\u001b[0m in \u001b[0;36mbuild_federated_averaging_process\u001b[0;34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weight_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m   return optimizer_utils.build_model_delta_optimizer_process(\n\u001b[1;32m    207\u001b[0m       \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_fed_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_optimizer_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m       stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36mbuild_model_delta_optimizer_process\u001b[0;34m(model_fn, model_to_client_delta_fn, server_optimizer_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0mserver_state_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_init_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_state_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtf_client_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_model_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \"\"\"Performs client local model optimization.\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0marg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapper_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(fn, parameter_type, wrapper_fn)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;31m# Either we have a concrete parameter type, or this is no-arg function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0mconcrete_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   py_typecheck.check_type(concrete_fn, function_utils.ConcreteFunction,\n\u001b[1;32m     92\u001b[0m                           'value returned by the wrapper')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper_instances.py\u001b[0m in \u001b[0;36m_tf_wrapper_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mctx_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_stack_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   comp_pb, extra_type_spec = tensorflow_serialization.serialize_py_fn_as_tf_computation(\n\u001b[0;32m---> 52\u001b[0;31m       target_fn, parameter_type, ctx_stack)\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcomputation_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputationImpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_type_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/tensorflow_serialization.py\u001b[0m in \u001b[0;36mserialize_py_fn_as_tf_computation\u001b[0;34m(target, parameter_type, context_stack)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_computation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorFlowComputationContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;31m# TODO(b/122081673): This needs to change for TF 2.0. We may also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    513\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Args to be bound must be in scope.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_unpack_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m       \u001b[0;31m# An interceptor function that verifies the actual parameter before it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m_unpack_and_call\u001b[0;34m(fn, arg_types, kwarg_types, arg)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 element_value, expected_type)\n\u001b[1;32m    507\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m       \u001b[0;31m# TODO(b/132888123): Consider other options to avoid possible bugs here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36mtf_client_delta\u001b[0;34m(tf_dataset, initial_model_weights)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \"\"\"\n\u001b[1;32m    381\u001b[0m     \u001b[0mclient_delta_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_client_delta_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0mclient_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_delta_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_model_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m               *args, **kwds)\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1713\u001b[0m               {\"PartitionedCall\": \"PartitionedCallUnused\",\n\u001b[1;32m   1714\u001b[0m                \"StatefulPartitionedCall\": \"PartitionedCallUnused\"}):\n\u001b[0;32m-> 1715\u001b[0;31m             \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m     \u001b[0mforward_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 executor_type=executor_type)\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m    857\u001b[0m           \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m           \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m           executor_type=executor_type)\n\u001b[0m\u001b[1;32m    860\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[0;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                    \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                    executor_type=executor_type, name=name)\n\u001b[0m\u001b[1;32m    602\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5881\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5816\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[0;32m-> 5818\u001b[0;31m                      (item, original_item))\n\u001b[0m\u001b[1;32m   5819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor(\"cnn/conv2d/kernel:0\", shape=(), dtype=resource) must be from the same graph as Tensor(\"Placeholder:0\", shape=(), dtype=variant)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzJXeJNSlGpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#获得初始状态\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpUydYwQnfHd",
        "colab_type": "code",
        "outputId": "eee5ad9d-62e1-47c6-8c36-88b6953501be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#查看第一轮训练\n",
        "sample_clients = random.sample(emnist_train.client_ids, NUM_CLIENTS)\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round 1, metrics={}'.format(metrics))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 1, metrics=<num_examples=5270.0,loss=2.3192951679229736,accuracy=0.1318785548210144>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkoGLYGLyYkC",
        "colab_type": "code",
        "outputId": "cca7e9f6-74cc-4616-9fe1-3d3f4d443907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#计算更多轮\n",
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2,NUM_ROUNDS):\n",
        "  #随机选择NUM_CLIENTS个用户\n",
        "  sample_clients = random.sample(emnist_train.client_ids, NUM_CLIENTS)\n",
        "  federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  2, metrics=<num_examples=5055.0,loss=2.2916009426116943,accuracy=0.1705242395401001>\n",
            "round  3, metrics=<num_examples=5215.0,loss=2.298238515853882,accuracy=0.14439117908477783>\n",
            "round  4, metrics=<num_examples=4450.0,loss=2.3351666927337646,accuracy=0.1323595494031906>\n",
            "round  5, metrics=<num_examples=5080.0,loss=2.2978105545043945,accuracy=0.15216535329818726>\n",
            "round  6, metrics=<num_examples=4860.0,loss=2.3288588523864746,accuracy=0.13724279403686523>\n",
            "round  7, metrics=<num_examples=5325.0,loss=2.305818557739258,accuracy=0.13971830904483795>\n",
            "round  8, metrics=<num_examples=5100.0,loss=2.306328535079956,accuracy=0.15529412031173706>\n",
            "round  9, metrics=<num_examples=5065.0,loss=2.323202133178711,accuracy=0.13780848681926727>\n",
            "round 10, metrics=<num_examples=5045.0,loss=2.2971935272216797,accuracy=0.16233894228935242>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKKb6c6h0AMF",
        "colab_type": "code",
        "outputId": "4680b305-b298-49e1-e2cc-e3846921ff9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "'''\n",
        "#使用tensorboard可视化\n",
        "#使用Tensorboard可视化这些联邦计算的度量\n",
        "#创建目录和相应的摘要编写器\n",
        "#@test {\"skip\": true}\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "#!!!太坑了，我以为@test是无关紧要的东西，emmm，就省略了，没想到就凉凉\n",
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    #随机选择用户\n",
        "    sample_clients = random.sample(emnist_train.client_ids, NUM_CLIENTS)\n",
        "    federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "\n",
        "    print('round {:2d}, metrics={}'.format(round_num, metrics))\n",
        "\n",
        "    for name, value in metrics._asdict().items():\n",
        "      tf.summary.scalar(name, value, step=round_num)\n",
        "\n",
        "#这个tensorBoard像有猫病一样，昨天还可以今天来突然就不行了\n",
        "#@test {\"skip\":true}\n",
        "#%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  1, metrics=<num_examples=5130.0,loss=3.049107074737549,accuracy=0.12222222238779068>\n",
            "round  2, metrics=<num_examples=4090.0,loss=2.928187370300293,accuracy=0.15843521058559418>\n",
            "round  3, metrics=<num_examples=5200.0,loss=2.9345836639404297,accuracy=0.14615385234355927>\n",
            "round  4, metrics=<num_examples=5140.0,loss=2.914067029953003,accuracy=0.14922179281711578>\n",
            "round  5, metrics=<num_examples=5080.0,loss=2.794748067855835,accuracy=0.1698818951845169>\n",
            "round  6, metrics=<num_examples=4775.0,loss=2.7447190284729004,accuracy=0.1736125648021698>\n",
            "round  7, metrics=<num_examples=5215.0,loss=2.490943193435669,accuracy=0.22205176949501038>\n",
            "round  8, metrics=<num_examples=5325.0,loss=2.353219985961914,accuracy=0.23868544399738312>\n",
            "round  9, metrics=<num_examples=4825.0,loss=2.181143045425415,accuracy=0.2878756523132324>\n",
            "round 10, metrics=<num_examples=5200.0,loss=2.17901873588562,accuracy=0.29750001430511475>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBGzrtDgP8hn",
        "colab_type": "code",
        "outputId": "c6a06970-3f1a-42b1-9247-a934649ee9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2020-04-01 01:27:33.614596: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
              "2020-04-01 01:27:33.614725: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
              "2020-04-01 01:27:33.614739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
              "Traceback (most recent call last):\n",
              "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
              "    sys.exit(run_main())\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 66, in run_main\n",
              "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
              "    _run_main(main, args)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
              "    sys.exit(main(argv))\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 268, in main\n",
              "    return runner(self.flags) or 0\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 282, in _run_serve_subcommand\n",
              "    server = self._make_server()\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 361, in _make_server\n",
              "    self.assets_zip_provider)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 165, in standard_tensorboard_wsgi\n",
              "    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 234, in TensorBoardWSGIApp\n",
              "    return TensorBoardWSGI(tbplugins, flags.path_prefix)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 286, in __init__\n",
              "    raise ValueError('Duplicate plugins for name %s' % plugin.plugin_name)\n",
              "ValueError: Duplicate plugins for name whatif"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}