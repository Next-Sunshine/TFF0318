{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTFTest-Github-a2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGh6RDzfDDL3frEe8Y9kT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TTF0318/blob/master/TTFTest_Github_a2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBPMpi1xw0zW",
        "colab_type": "code",
        "outputId": "65d50e24-6d69-45c8-80a8-33e211e2f490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#@test{\"skip\":true}\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 2.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 89.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 45.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 45.0MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QyDgFLw-pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "#TODO(b/148678573,b/148685415):must use the ReferenceExecutor because\n",
        "#it supports unbounded references and tff.sequence_* intrinsics\n",
        "tff.framework.set_default_executor(tff.framework.ReferenceExecutor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRTbABCw_fn",
        "colab_type": "code",
        "outputId": "1a30e7c3-99eb-43d6-a716-81a64118d74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "hello_world()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9FlqOxxBv9",
        "colab_type": "code",
        "outputId": "078bd64c-545e-4844-a9a3-f1e9ac5e5fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#加载MNIST数据集\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_axy866xFst",
        "colab_type": "code",
        "outputId": "f3fb9a98-bfde-4c26-da15-4b8ddc058c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x.dtype应该是数据类型，uint8是8位无符号整型，x.shape是在打印x的维度\n",
        "[(x.dtype, x.shape) for x in mnist_train]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7P7TMLxGVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch翻译为批，CNN是分批处理，batch_size就是每批处理的大小\n",
        "#NUM_EXAMPLES_PER_USER是每个用户的样本数，每个用户有1000个样本，每次处理100个\n",
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_data_for_digit(source,digit):\n",
        "  output_sequence = []\n",
        "  #如果没有猜错，i代表的是客户端的序号，d代表的是数字\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i+ BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x':\n",
        "        #flatten（）函数用于降维，返回一个一维数组，默认是按行的方向降维\n",
        "        np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                 dtype = np.float32),\n",
        "        'y':\n",
        "        np.array([source[1][i] for i in batch_samples], dtype= np.int32)\n",
        "    })\n",
        "  return output_sequence\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf5jsd3ZxKJG",
        "colab_type": "code",
        "outputId": "4b5f24dd-f546-4f26-8572-fa963a740610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#查看第5个客户端提供的最后一批数据中的Y张量，输出结果有100个5，说明每个客户端100张图片\n",
        "#-1代表最后一列,好处是不知道一共有多少列也可以选定，一列是一批？\n",
        "federated_train_data[5][-1]['y']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJhzapqxK8J",
        "colab_type": "code",
        "outputId": "ae117f70-950f-4c65-95c3-fe0436092d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#查看与该批次相对应的最后一个元素相对应的图像\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28,28), cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZaEZGfuiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrHhlkDxM9k",
        "colab_type": "code",
        "outputId": "1a59a9e7-a337-4c86-b6e2-b66a82584191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#定义批的tff类型\n",
        "#OrderedDict根据传入的顺序安排字典，而不是按照字母顺序安排字典\n",
        "BATCH_SPEC = collections.OrderedDict(\n",
        "    #维度设置为None表示大小未知,784列，数据类型为32位浮点\n",
        "    x = tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "    y = tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
        ")\n",
        "#to_type将指定类型转换成tff类型\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "#BATCH_TYPE是一个二维的数组x和一个一维的数组y\n",
        "str(BATCH_TYPE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<x=float32[?,784],y=int32[?]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klk_oXp0xO7t",
        "colab_type": "code",
        "outputId": "1f592b13-8d74-449c-dd53-4a30b64da043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#定义模型的tff类型\n",
        "MODEL_SPEC = collections.OrderedDict(\n",
        "    weights = tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
        "    bias = tf.TensorSpec(shape=[10], dtype=tf.float32)\n",
        ")\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights=float32[784,10],bias=float32[10]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIb6UGiVxQ2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: 'forward_pass' is defined separately from 'batch_loss'\n",
        "#so that it can be later called from within another tf.function.\n",
        "#Necessary because a @tf.function decorated method cannot\n",
        "# invoke a @tff.tf_computation.\n",
        "#@tf.function将一个函数编译成一个可调用的TensorFlow图？示例代码说的是可以使函数中的类型\n",
        "#在对应位按照定义的函数操作且最后数据类型不变，数组对应位操作完了仍然是数组\n",
        "#forward_pass是使用前向传播计算损失？\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  #tf.nn.softmax把一个N*1的向量归一化为（0,1）之间的特征值使得向量中数值较大的量特征更明显\n",
        "  #softmax输出向量的意思就是样本属于每个类的概率\n",
        "  predicted_y = tf.nn.softmax(\n",
        "      #batch为什么会有‘x'\n",
        "      #tf.matmul是线代矩阵相乘，应满足矩阵相乘条件且元素类型相同，返回一个新矩阵，tf.multiply则是矩阵的对应元素相乘\n",
        "      tf.matmul(batch['x'], model['weights']) + model['bias']\n",
        "  )\n",
        "  #reduce_mean(tensor,axis,Keepdim,name)降维计算数组的平均值,axis控制轴，没有则计算所有数的平均值返回一个数，\n",
        "  #0按列计算平均值，返回列个数，1按行计算平均值返回行个数\n",
        "  #其实应该是0代表第一个[[1,1,1],[1,1,1]]维度,去掉第一个[]即[1+1,1+1,1+1],1则第二个维度[1+1+1,1+1+1]去掉第第一二个[]\n",
        "  return -tf.reduce_mean(\n",
        "      #reduce_sum(tensor,axis,Keepdim,name)降维计算张量的总和\n",
        "      tf.reduce_sum(\n",
        "      #构造一个独热码，batch['y']指示的地方是1，其他地方是0\n",
        "      tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1])\n",
        "  )\n",
        "#定义tff类型的函数，输入值是MODEL_TYPE类型和BATCH_TYPE类型\n",
        "#用@tff.computation修饰的函数调用@tf.function修饰的函数，是因为@tff修饰的函数里面不能有tf的数据类型？\n",
        "#batch_loss函数计算损失\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2cD0ytyxS7u",
        "colab_type": "code",
        "outputId": "2f15a264-be88-495d-ea1d-6094145ceb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#signature告诉我们，batch_loss接受一个列表作为输入，列表里面还有两个小列表，分别放着权重偏斜、xy然后返回一个32位的浮点损失\n",
        "str(batch_loss.type_signature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-2K8j3xVTp",
        "colab_type": "code",
        "outputId": "e89ffeae-0dcc-4f78-a671-bec8f4e2a699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#初始模型，使用特定大小的以0填充初始化\n",
        "initial_model = collections.OrderedDict(\n",
        "    #np.zeros()返回一个给定形状的用0填充的数组，这里为什么要用0来填充权重和偏斜\n",
        "    weights = np.zeros([784, 10], dtype=np.float32),\n",
        "    bias = np.zeros([10], dtype=np.float32)\n",
        ")\n",
        "#批样本使用训练数据的第五行最后一列，为什么？\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UufkeLuoxXCa",
        "colab_type": "code",
        "outputId": "ab84d6c2-7e75-464a-ac1b-620a6620b60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#定义一个计算，使用损失函数执行单步梯度下降，batch_train函数更新权重和偏移，接收一个BATCH_TYPE进行训练，后面的local_train接收一群BATCH_TYPE\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  #Define a group of model variables and set them to 'initial_model'\n",
        "  #Must be defined outside the @tf.function.\n",
        "  #什么意思？？定义一组模型变量（name，value）进initial_model？那里面的name和value值从哪儿来？？\n",
        "  model_vars = collections.OrderedDict([\n",
        "      #tf.Variable()构造一个变量添加进图中，通过构造以后该变量的形状和类型不能改但是可以通过assign函数改\n",
        "      (name, tf.Variable(name=name, initial_value=value))\n",
        "      for name, value in initial_model.items()                                  \n",
        "  ])\n",
        "  #tf.keras.optimizers.SGD（）执行随机梯度下降和动量优化\n",
        "  #实例化一个优化函数并基于一定的学习率进行训练\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  #此处定义函数_train_on_batch()但是并没有调用，所以在后面return的时候才是调用\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from batch_loss（从batch_loss中使用loss执行单步梯度下降）\n",
        "    #使用tf.GradientTape计算梯度\n",
        "    with tf.GradientTape() as tape:\n",
        "      #forward_pass（）使用前向传播的方式计算损失？？？\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    #.gradient执行求导操作\n",
        "    #grads相当于dloss/dmodel_vars,即loss对model_vars求导\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    #apply_gradients(grads_and_vars, global_step=None, name=None)将计算出的梯度应用到变量上（计算变量为某一定值时的梯度）,对global_step作自增操作\n",
        "    optimizer.apply_gradients(\n",
        "        #zip([iterator1,iterator2,]) 将可迭代对象中对应的元素打包成一个元组，返回有这些元组组成的对象，用list把这个对象转化成列表\n",
        "        #例如a=[1,2,3]b=[4,5,6],zip(a,b)=[(1,4),(2,5),(3,6)]\n",
        "        #flatten用于降维，返回一个一维数组，默认按行降维\n",
        "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)) )\n",
        "    #这里返回model_vars，这个变量哪里被改变了？\n",
        "    return model_vars\n",
        "    \n",
        "  return _train_on_batch(model_vars, batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIoKDTSxZFP",
        "colab_type": "code",
        "outputId": "2f5e56b8-aa60-4719-cc18-7b7209fa6b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#输入<权重,偏移>model、<x,y>batch，输出权重和偏移也就是新模型，batch_train是在更新权重和偏移\n",
        "str(batch_train.type_signature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>,float32> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGg9jVqmxb93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#最开始使用初始化模型，sample_batch的初始值为federated_train_data[5][-1]\n",
        "#将batch_train多次应用于初始模型，看损失是否减少\n",
        "model = initial_model\n",
        "loses = []\n",
        "for _ in range(5):\n",
        "  #batch_train更新权重和偏移，但是返回值model_vars没有看到在哪里被改变\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  loses.append(batch_loss(model, sample_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSkQCJTxfu8",
        "colab_type": "code",
        "outputId": "454a15dd-bd7a-4f93-b2c6-8389a7bb1cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19690023, 0.13176315, 0.10113225, 0.08273812, 0.07030139]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "freff1NExgWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构造一个序列化，则LOCAL_DATA_TYPE代表了一群BATCH_TYPE，来自一个用户的所有批的整个序列计算\n",
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "  #Mapping function to apply to each batch.\n",
        "  #定义batch_fn函数使用一个batch进行训练，更新模型参数\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "  #tff.sequence.reduce(value,zero,fn)在给定zero和操作fn的情况下对value进行操作以减少序列值\n",
        "  #tff.sequence.reduce和tf.data.Dataset.reduce作用差不多，只是前面一个用于联邦计算，联邦计算里面不能包含TensorFlow代码\n",
        "  #此处不停将batch_fn应用于all_batches中的每一个元素和initial然后将得到的结果赋值给initial_model？\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOS6tzRxiVV",
        "colab_type": "code",
        "outputId": "59aca9c8-a0fd-456e-a467-81bfcd9cfca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#local_train返回的是<权重,偏移>，则返回值是模型\n",
        "str(local_train.type_signature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,float32,<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ilW11k4xkEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#federated_test_data[5]代表的是一个用户的所有batch，local_train计算了一个用户的所有batch\n",
        "locally_trained_model = local_train(initial_model, 0.1, federated_test_data[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8Wg7u_xmAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOCAL_DATA_TYPE代表一群batch，即每个用户的所有batch序列\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  #TODO(b/120157713):Replace with tff.sequence_average() once implemented.\n",
        "  #tff.sequence.sum则计算loss的总和，这里是计算某个模型在特定数据集上面的表现\n",
        "  return tff.sequence_sum(\n",
        "      tff.sequence_map(\n",
        "          #lambda匿名函数:之前代表是匿名函数的参数\n",
        "          #将匿名函数应用到all_batches里面的每一个batch，然后会得到loss\n",
        "          tff.federated_computation(lambda b: batch_loss(model, b),BATCH_TYPE),\n",
        "          all_batches\n",
        "      )\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILv4hi8Lxn9Q",
        "colab_type": "code",
        "outputId": "155b4351-773a-4717-9813-ab907ae335cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#signature表明，local_eval函数接收一个模型，一群batch作为输入最后返回一个32位浮点（损失）\n",
        "str(local_eval.type_signature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>*> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZvDC9Ixpv6",
        "colab_type": "code",
        "outputId": "3d5bde30-ebf7-4662-97a3-bb0a16425075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#初始模型\n",
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[5]))\n",
        "#进行了第五个用户所有batch训练之后的模型\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 0.57459134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdFW-VgXzjZz",
        "colab_type": "code",
        "outputId": "f664abaa-a8bc-4207-cc9e-2f1b419621b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#查看该模型在其他数据集上面的表现，表明为用户5训练的locally_trained_model只会识别5，泛化能力差\n",
        "#问题：从全球的角度看，本地模型时如何影响模型质量\n",
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[0]))\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 72.66378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WSkaaSQ0HHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#定义服务器模型类型，MODEL_TYPE@SERVER\n",
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
        "#定义客户端数据类型，LOCAL_DATA_TYPE(一群batch)@CLIENTS\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9XhCnKJ0nj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#又定义federated_eval此时接收服务器的模型和客户端的batch\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE,CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  #federated_mean计算所有客户端的平均损失\n",
        "  return tff.federated_mean(\n",
        "      #tff.federated_broadcast将模型分发给客户机，让每个客户机对本地的数据调用本地计算，相当于{model_type@CLIENTS}\n",
        "      #有一个问题是怎么知道哪个客户机对应的data\n",
        "      #{model_type@CLIENTS，data_type@CLIENTS}和{<model，data>@CLIENTS}等价，前面那个会发生隐式转换，相当于调用了tff.federated_zip\n",
        "      #local_eval(model，all_batches)，federated_map将local_eval应用到每个客户端计算每个客户端的损失\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdjtsv_C1xxq",
        "colab_type": "code",
        "outputId": "d1c249f0-3b92-4ac1-bf81-80d467d9264a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model loss=', federated_eval(initial_model, federated_train_data))\n",
        "print('locally_trained_model, loss=', federated_eval(locally_trained_model, federated_train_data))\n",
        "#通过结果可以看出，损失增加，所以要改进每个用户的模型，需要对每个人的数据进行培训"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025852\n",
            "locally_trained_model, loss= 52.793297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8fMAKx2bgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#实现联合训练最简单的方法是本地训练然后对模型进行平均\n",
        "#构造一个SERVER_FLOAT_TYPE服务器数据类型，是一个放置在SERVER上的32位浮点\n",
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
        "#该函数接收三个参数，放置在SERVER上的模型和浮点数，放置在CLIENT上面的一群batch（分别是模型，浮点数，训练数据）\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  #前面已经说过，tff.federated_mean是计算model的联邦平均，最后求权重和偏移的平均？\n",
        "  return tff.federated_mean(\n",
        "      #此处相当于tff.federated_map(local_train，[{model,learning_rate,data}@CLIENTS])\n",
        "      #local_train是在给定的模型中以给定的学习率训练batch，然后返回一个model\n",
        "      tff.federated_map(local_train, [tff.federated_broadcast(model),tff.federated_broadcast(learning_rate),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lrjTBPM50ne",
        "colab_type": "code",
        "outputId": "ee598b3c-ea20-49d7-de59-1a7d3d57e50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#开始真正的fed训练：进行几轮训练并比较前后的平均损失\n",
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "for round_num in range(5):\n",
        "  #每一轮将大家的模型分别更新，取平均之后又拿回来，federated_train_data是MNIST数据集里面的训练数据\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  #更新学习率\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  #计算loss\n",
        "  loss = federated_eval(model, federated_train_data)\n",
        "  print('round{}, loss={}'.format(round_num, loss))\n",
        "  #下一轮统一的模型又还给各位CLIENTS去更新"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round0, loss=21.60552406311035\n",
            "round1, loss=20.365678787231445\n",
            "round2, loss=19.27480125427246\n",
            "round3, loss=18.31110954284668\n",
            "round4, loss=17.45725440979004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfoaHBsX9DRl",
        "colab_type": "code",
        "outputId": "f4553d21-3b12-404a-dd42-fe60323f2a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#在训练出来的模型上运行测试数据\n",
        "print('initial_model test loss=', federated_eval(initial_model, federated_test_data))\n",
        "print('trained_model test loss=', federated_eval(model, federated_test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test loss= 22.795593\n",
            "trained_model test loss= 17.278767\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}