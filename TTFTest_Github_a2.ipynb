{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTFTest-Github-a2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4gDG0XECYRx2GdeC/ltMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TTF0318/blob/master/TTFTest_Github_a2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBPMpi1xw0zW",
        "colab_type": "code",
        "outputId": "a2cf2c2a-4440-482a-cfe5-73bb2d13783b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#@test{\"skip\":true}\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 36kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 239kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 48.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 67.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QyDgFLw-pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "#TODO(b/148678573,b/148685415):must use the ReferenceExecutor because\n",
        "#it supports unbounded references and tff.sequence_* intrinsics\n",
        "#将执行器支持的执行上下文放在堆栈的顶部。\n",
        "tff.framework.set_default_executor(tff.framework.ReferenceExecutor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRTbABCw_fn",
        "colab_type": "code",
        "outputId": "ebdedc48-3488-4c50-bd7f-7682af2a4e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "hello_world()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9FlqOxxBv9",
        "colab_type": "code",
        "outputId": "69615142-817e-4dfd-d0ae-71bfbbf278ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#加载MNIST数据集\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_axy866xFst",
        "colab_type": "code",
        "outputId": "8e5f5ee3-8ac7-40b9-feb3-13228ac9f975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x.dtype应该是数据类型，uint8是8位无符号整型，x.shape是在打印x的维度\n",
        "[(x.dtype, x.shape) for x in mnist_train]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7P7TMLxGVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch翻译为批，CNN是分批处理，batch_size就是每批处理的大小\n",
        "#NUM_EXAMPLES_PER_USER是每个用户的样本数，每个用户有1000个样本，每次处理100个\n",
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "#source代表数据集，digit代表了数字，这个函数应该是根据数字找到对应的图片\n",
        "def get_data_for_digit(source,digit):\n",
        "  output_sequence = []\n",
        "  #如果没有猜错，i代表的是客户端的序号，d代表的是数字？？？\n",
        "  #第二次看：i应该是第i批，enumerate(source[1])返回的是source[1]里面的(数字，“对象\")这种类型\n",
        "  #我将mnist_train[1]打印出来看，发现是：array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)，这个存放的是图片的标识数字？那么source[0]存放的图片的形状？\n",
        "  #这里利用枚举类型将source中所有等于digit的数字对应的下标都取出来\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  #令i从0到三个数中最小的那个之间变化\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    #将all_samples中的样本按批次大小分批\n",
        "    batch_samples = all_samples[i:i+ BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x':\n",
        "        #flatten（）函数用于降维，返回一个一维数组，默认是按行的方向降维\n",
        "        #source[0]这里存放的是图片的矩阵形式？即转换成像素之类的数学表示\n",
        "        np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                 dtype = np.float32),\n",
        "        'y':\n",
        "        #source[1]存放的是用户图片的标识数字？\n",
        "        np.array([source[1][i] for i in batch_samples], dtype= np.int32)\n",
        "    })\n",
        "  return output_sequence\n",
        "#federated_train_data按照第几个用户第几批数据在存储\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf5jsd3ZxKJG",
        "colab_type": "code",
        "outputId": "34a5abd5-6099-4c28-f330-e7f92b980df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#查看第5个客户端提供的最后一批数据中的Y张量，输出结果有100个5，说明每个客户端100张图片\n",
        "#-1代表最后一列,好处是不知道一共有多少列也可以选定，一列是一批？\n",
        "#第0个客户端训练所有的图片0，第i个客户端训练i，每个客户端的训练数据都不一样\n",
        "federated_train_data[5][-1]['y']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86CyxA5XkJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e40836a0-f19d-4eac-9998-e36340d82f63"
      },
      "source": [
        "#查看第0个用户的训练数据，分成了超级多批，x放着图片（矩阵），y放着数字\n",
        "federated_train_data[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)},\n",
              " {'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'y': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyo9v8ZCquu0",
        "colab_type": "code",
        "outputId": "6b880dc4-6d90-46d8-e1c4-8bcd90fd9735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#这里看一下划分的mnist_train[1]是什么，发现就是一些识别图片的数字\n",
        "mnist_train[1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJhzapqxK8J",
        "colab_type": "code",
        "outputId": "1a41c750-ce39-43a5-822c-9081f1120852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#查看与该批次相对应的最后一个元素相对应的图像\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28,28), cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAN6UlEQVR4nO3dfaxU9Z3H8c/Ha4sijUHMEkLZRRuf\nGuNaJbqJZsHUVvQfqQRSjI26TW4TNKlmk13s/oHJutG4dNe/fKA+wK7VpkasRBdaV0jdxaTxalhF\n2VZWMfXmArpgwKeg8N0/7mFzxTu/ucyceYDv+5VMZuZ858z5Zrgfzpnzm5mfI0IAjn3H9boBAN1B\n2IEkCDuQBGEHkiDsQBLHd3Njtjn1D3RYRHi85W3t2W3Pt/1729tsL2vnuQB0llsdZ7c9IOkPkr4j\n6V1JL0laEhFvFNZhzw50WCf27BdJ2hYRb0XEfkm/kHR1G88HoIPaCftMSX8cc//datkX2B60PWR7\nqI1tAWhTx0/QRcRKSSslDuOBXmpnzz4sadaY+1+vlgHoQ+2E/SVJZ9g+zfZXJX1f0tp62gJQt5YP\n4yPic9s3S/q1pAFJD0fE67V1BqBWLQ+9tbQx3rMDHdeRD9UAOHoQdiAJwg4kQdiBJAg7kARhB5Ig\n7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEV6ds\nRv+56aabivWPPvqoWF+1alWN3XzR7Nmzi/XjjivvqxYvXtywNnPml2Yq+4KlS5cW65dffnmxvnHj\nxmK9F9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMnt2DBgmL9sssuK9anTZtWrG/evLlh7dpr\nry2ue9111xXrAwMDxXo7Pvzww2J9z549Hdt2p7QVdtvbJe2TdEDS5xExp46mANSvjj37ZRHxfg3P\nA6CDeM8OJNFu2EPSb2y/bHtwvAfYHrQ9ZHuozW0BaEO7h/GXRsSw7T+R9Jzt/46IF8Y+ICJWSlop\nSbajze0BaFFbe/aIGK6ud0l6StJFdTQFoH4th932Sba/dui2pO9K2lJXYwDq1c5h/HRJT9k+9DyP\nRcT6WrrCUePuu+8u1iP6853brbfeWqyvW7euWN+2bVud7XRFy2GPiLck/XmNvQDoIIbegCQIO5AE\nYQeSIOxAEoQdSIKvuB4DquHPcV1yySXFdefOnVt3OxP2ySefFOv79u0r1tevL4/03nHHHQ1rb7/9\ndnHdfh0ybAd7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1Iwt0cT+SXajpjypQpDWsffPBBR7e9f//+\nYn3t2rUNaytWrCiuOzTEL5m1IiLG/eAFe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILvsx8DFi1a\n1LNtL126tFhftWpVdxpBU+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmPAosXLy7W77nnno5t\n+9577y3WGUc/ejTds9t+2PYu21vGLDvF9nO236yup3a2TQDtmshh/CpJ8w9btkzS8xFxhqTnq/sA\n+ljTsEfEC5J2H7b4akmrq9urJS2ouS8ANWv1Pfv0iBipbu+QNL3RA20PShpscTsAatL2CbqIiNIP\nSUbESkkrJX5wEuilVofedtqeIUnV9a76WgLQCa2Gfa2k66vb10t6up52AHRK09+Nt/24pHmSTpW0\nU9JySb+S9EtJfyrpHUmLI+Lwk3jjPReH8eOYPHlysf7iiy8W6+eee27L296wYUOxvnDhwmK92Rzq\n6L5Gvxvf9D17RCxpUPp2Wx0B6Co+LgskQdiBJAg7kARhB5Ig7EASfMW1CyZNmlSsP/DAA8V6O0Nr\nzdx5553FOkNrxw727EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsXTBv3rxifcmSRl8s7Lxrrrmm\nWD/vvPOK9b179xbrjzzyyBH3hM5gzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTT9KelaN5b0p6Sf\nffbZYn3+/MPnzTx6HHdceX/x9NONpxRo9ro89NBDxfrBgweL9awa/ZQ0e3YgCcIOJEHYgSQIO5AE\nYQeSIOxAEoQdSIJx9i644IILivX77ruvWL/wwgtb3vbWrVuL9ZGRkWJ91qxZxfqZZ55ZrLfz97Vs\n2bJifcWKFS0/97Gs5XF22w/b3mV7y5hlt9setr25ulxVZ7MA6jeRw/hVksb7iNc/R8T51eXf6m0L\nQN2ahj0iXpC0uwu9AOigdk7Q3Wz71eowf2qjB9ketD1ke6iNbQFoU6thv0/SNySdL2lE0k8bPTAi\nVkbEnIiY0+K2ANSgpbBHxM6IOBARByX9TNJF9bYFoG4thd32jDF3vydpS6PHAugPTcfZbT8uaZ6k\nUyXtlLS8un++pJC0XdKPIqI8YKu84+zNTJ48uVg//fTTW37u4eHhYn3Pnj3F+rRp04r1s846q1i/\n7bbbGtauvPLK4roHDhwo1hcsWFCsr1u3rlg/VjUaZ286SUREjDeDQflXBQD0HT4uCyRB2IEkCDuQ\nBGEHkiDsQBJ8xbUGJ554YrH+6aefFuvd/DfotoGBgYa1zZs3F9c955xzivVNmzYV63Pnzi3Wj1X8\nlDSQHGEHkiDsQBKEHUiCsANJEHYgCcIOJNH0W28YdfLJJzesPfbYY8V1Fy1aVKx//PHHLfV0NJgy\nZUrD2gknnNDWcx9/PH++R4I9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwUDlBM2Z03hCmyuuuKK4\nbrNpjZt9r7uflcbRJenRRx9tWDvttNPqbgcF7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2btg\n/fr1xXppWmNJeuKJJ+ps54jccMMNxfry5cuL9alTp7a87c8++6xYv//++1t+7oya7tltz7K90fYb\ntl+3/eNq+Sm2n7P9ZnXd+r8qgI6byGH855L+OiK+KekvJN1k+5uSlkl6PiLOkPR8dR9An2oa9ogY\niYhXqtv7JG2VNFPS1ZJWVw9bLWlBp5oE0L4jes9ue7akb0n6naTpETFSlXZImt5gnUFJg623CKAO\nEz4bb3uKpCcl3RIRe8fWYnRmwnFnJ4yIlRExJyIaf5MEQMdNKOy2v6LRoP88ItZUi3fanlHVZ0ja\n1ZkWAdSh6ZTNtq3R9+S7I+KWMcv/UdL/RsRdtpdJOiUi/qbJcx21cxNffPHFDWsbNmworjtp0qS6\n2+kbo38ejZX+vvbs2VNct9mQ5IMPPlisZ9VoyuaJvGe/RNIPJL1m+9AXr38i6S5Jv7T9Q0nvSFpc\nR6MAOqNp2CPiPyU1+u/72/W2A6BT+LgskARhB5Ig7EAShB1IgrADSTQdZ691Y0fxOHvJjTfeWKw3\n+yrmwMBAne10VbNx9vfee69hbeHChcV1N23a1FJP2TUaZ2fPDiRB2IEkCDuQBGEHkiDsQBKEHUiC\nsANJMM7eBWeffXaxvmbNmmK92ZTPndRsOulnnnmmWC99xmDHjh0t9YQyxtmB5Ag7kARhB5Ig7EAS\nhB1IgrADSRB2IAnG2YFjDOPsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5BE07DbnmV7o+03bL9u+8fV\n8tttD9veXF2u6ny7AFrV9EM1tmdImhERr9j+mqSXJS3Q6HzsH0bEiglvjA/VAB3X6EM1E5mffUTS\nSHV7n+2tkmbW2x6ATjui9+y2Z0v6lqTfVYtutv2q7YdtT22wzqDtIdtDbXUKoC0T/my87SmSfivp\nHyJije3pkt6XFJL+XqOH+n/V5Dk4jAc6rNFh/ITCbvsrkp6R9OuI+Kdx6rMlPRMR5zZ5HsIOdFjL\nX4Tx6DSdD0naOjbo1Ym7Q74naUu7TQLonImcjb9U0n9Iek3SwWrxTyQtkXS+Rg/jt0v6UXUyr/Rc\n7NmBDmvrML4uhB3oPL7PDiRH2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS\nIOxAEoQdSKLpD07W7H1J74y5f2q1rB/1a2/92pdEb62qs7c/a1To6vfZv7Rxeygi5vSsgYJ+7a1f\n+5LorVXd6o3DeCAJwg4k0euwr+zx9kv6tbd+7Uuit1Z1pbeevmcH0D293rMD6BLCDiTRk7Dbnm/7\n97a32V7Wix4asb3d9mvVNNQ9nZ+umkNvl+0tY5adYvs5229W1+POsdej3vpiGu/CNOM9fe16Pf15\n19+z2x6Q9AdJ35H0rqSXJC2JiDe62kgDtrdLmhMRPf8Ahu2/lPShpH85NLWW7bsl7Y6Iu6r/KKdG\nxN/2SW+36win8e5Qb42mGb9BPXzt6pz+vBW92LNfJGlbRLwVEfsl/ULS1T3oo+9FxAuSdh+2+GpJ\nq6vbqzX6x9J1DXrrCxExEhGvVLf3STo0zXhPX7tCX13Ri7DPlPTHMfffVX/N9x6SfmP7ZduDvW5m\nHNPHTLO1Q9L0XjYzjqbTeHfTYdOM981r18r05+3iBN2XXRoRF0i6UtJN1eFqX4rR92D9NHZ6n6Rv\naHQOwBFJP+1lM9U0409KuiUi9o6t9fK1G6evrrxuvQj7sKRZY+5/vVrWFyJiuLreJekpjb7t6Cc7\nD82gW13v6nE//y8idkbEgYg4KOln6uFrV00z/qSkn0fEmmpxz1+78frq1uvWi7C/JOkM26fZ/qqk\n70ta24M+vsT2SdWJE9k+SdJ31X9TUa+VdH11+3pJT/ewly/ol2m8G00zrh6/dj2f/jwiun6RdJVG\nz8j/j6S/60UPDfo6XdJ/VZfXe92bpMc1elj3mUbPbfxQ0jRJz0t6U9K/Szqlj3r7V41O7f2qRoM1\no0e9XarRQ/RXJW2uLlf1+rUr9NWV142PywJJcIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4P6qF\nZaEZGfuiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFnX7HPBuZhD",
        "colab_type": "code",
        "outputId": "6d588b9b-c92b-4982-84b0-881d25ff0fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#倒数第二个数也是图片5，又印证了第5个用户识别的图片是5\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-2].reshape(28,28), cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHUiCsANJ/D8bj27SYd0X8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrHhlkDxM9k",
        "colab_type": "code",
        "outputId": "dd88e6e5-c4ad-4709-b95e-b0e5c5b46941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#定义批的tff类型\n",
        "#OrderedDict根据传入的顺序安排字典，而不是按照字母顺序安排字典,这里指定批的形状\n",
        "BATCH_SPEC = collections.OrderedDict(\n",
        "    #维度设置为None表示大小未知,784列，数据类型为32位浮点\n",
        "    #tf.TensorSpec(shape,dtype)指定输入的数据形状和类型，如果类型不匹配则会出错，这里指定x和y的类型\n",
        "    x = tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "    y = tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
        ")\n",
        "#to_type将指定类型转换成tff类型\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "#BATCH_TYPE是一个二维的数组x和一个一维的数组y\n",
        "str(BATCH_TYPE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<x=float32[?,784],y=int32[?]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klk_oXp0xO7t",
        "colab_type": "code",
        "outputId": "f50d54f5-8df6-44c1-925b-9ce18b95f936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#定义模型的tff类型\n",
        "#指定模型的类型\n",
        "MODEL_SPEC = collections.OrderedDict(\n",
        "    weights = tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
        "    #shape=10是只有10个元素的列表吗？\n",
        "    bias = tf.TensorSpec(shape=[10], dtype=tf.float32)\n",
        ")\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights=float32[784,10],bias=float32[10]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIb6UGiVxQ2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: 'forward_pass' is defined separately from 'batch_loss'\n",
        "#so that it can be later called from within another tf.function.\n",
        "#Necessary because a @tf.function decorated method cannot\n",
        "# invoke a @tff.tf_computation.\n",
        "#@tf.function将一个函数编译成一个可调用的TensorFlow图？示例代码说的是可以使函数中的类型\n",
        "#在对应位按照定义的函数操作且最后数据类型不变，数组对应位操作完了仍然是数组\n",
        "#forward_pass是使用前向传播计算损失？\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  #tf.nn.softmax把一个N*1的向量归一化为（0,1）之间的特征值使得向量中数值较大的量特征更明显\n",
        "  #softmax输出向量的意思就是样本属于每个类的概率\n",
        "  predicted_y = tf.nn.softmax(\n",
        "      #batch为什么会有‘x'，batch是批数据，数据里面是有x和y的\n",
        "      #tf.matmul是线代矩阵相乘，应满足矩阵相乘条件且元素类型相同，返回一个新矩阵，tf.multiply则是矩阵的对应元素相乘\n",
        "      #x（图片）×权重+偏移，但是x×权重的形状是None行10列，bias的形状是10个元素的数组，二者可以加吗？\n",
        "      tf.matmul(batch['x'], model['weights']) + model['bias']\n",
        "  )\n",
        "  #reduce_mean(tensor,axis,Keepdim,name)降维计算数组的平均值,axis控制轴，没有则计算所有数的平均值返回一个数，\n",
        "  #0按列计算平均值，返回列个数，1按行计算平均值返回行个数\n",
        "  #其实应该是0代表第一个[[1,1,1],[1,1,1]]维度,去掉第一个[]即[1+1,1+1,1+1],1则第二个维度[1+1+1,1+1+1]去掉第第一二个[]\n",
        "  return -tf.reduce_mean(\n",
        "      #reduce_sum(tensor,axis,Keepdim,name)降维计算张量的总和\n",
        "      tf.reduce_sum(\n",
        "      #构造一个独热码，batch['y']指示的地方是1，其他地方是0\n",
        "      tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1])\n",
        "  )\n",
        "#定义tff类型的函数，输入值是MODEL_TYPE类型和BATCH_TYPE类型\n",
        "#用@tff.computation修饰的函数调用@tf.function修饰的函数，是因为@tff修饰的函数里面不能有tf的数据类型？\n",
        "#batch_loss函数计算损失\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2cD0ytyxS7u",
        "colab_type": "code",
        "outputId": "b850f186-b0b3-4f16-ab47-526c82f61937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#signature告诉我们，batch_loss接受一个列表作为输入，列表里面还有两个小列表，分别放着权重偏斜、xy然后返回一个32位的浮点损失\n",
        "str(batch_loss.type_signature)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-2K8j3xVTp",
        "colab_type": "code",
        "outputId": "608665b6-e8de-404b-ae77-7468a7e91bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#初始模型，使用特定大小的以0填充初始化\n",
        "initial_model = collections.OrderedDict(\n",
        "    #np.zeros()返回一个给定形状的用0填充的数组，这里为什么要用0来填充权重和偏斜,可能0代表初始化的值\n",
        "    weights = np.zeros([784, 10], dtype=np.float32),\n",
        "    bias = np.zeros([10], dtype=np.float32)\n",
        ")\n",
        "#批样本使用训练数据的第五个用户的最后一列，每一列为1批？\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UufkeLuoxXCa",
        "colab_type": "code",
        "outputId": "25d8ef4c-470f-4e79-a9ac-582610d649da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#定义一个计算，使用损失函数执行单步梯度下降，batch_train函数更新权重和偏移，接收一个BATCH_TYPE进行训练，后面的local_train接收一群BATCH_TYPE\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  #Define a group of model variables and set them to 'initial_model'\n",
        "  #Must be defined outside the @tf.function.\n",
        "  #什么意思？？定义一组模型变量（name，value）进initial_model？那里面的name和value值从哪儿来？？\n",
        "  model_vars = collections.OrderedDict([\n",
        "      #tf.Variable()构造一个变量添加进图中，通过构造以后该变量的形状和类型不能改但是可以通过assign函数改\n",
        "      (name, tf.Variable(name=name, initial_value=value))\n",
        "      for name, value in initial_model.items()                                  \n",
        "  ])\n",
        "  #tf.keras.optimizers.SGD（）执行随机梯度下降和动量优化\n",
        "  #实例化一个优化函数并基于一定的学习率进行训练\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  #此处定义函数_train_on_batch()但是并没有调用，所以在后面return的时候才是调用\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from batch_loss（从batch_loss中使用loss执行单步梯度下降）\n",
        "    #使用tf.GradientTape计算梯度\n",
        "    with tf.GradientTape() as tape:\n",
        "      #forward_pass（）使用前向传播的方式计算损失？？？\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    #.gradient执行求导操作\n",
        "    #grads相当于dloss/dmodel_vars,即loss对model_vars求导\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    #apply_gradients(grads_and_vars, global_step=None, name=None)将计算出的梯度应用到变量上（计算变量为某一定值时的梯度）,对global_step作自增操作\n",
        "    optimizer.apply_gradients(\n",
        "        #zip([iterator1,iterator2,]) 将可迭代对象中对应的元素打包成一个元组，返回有这些元组组成的对象，用list把这个对象转化成列表\n",
        "        #例如a=[1,2,3]b=[4,5,6],zip(a,b)=[(1,4),(2,5),(3,6)]\n",
        "        #flatten用于降维，返回一个一维数组，默认按行降维，model_vars有weight和bias\n",
        "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)) )\n",
        "    #这里返回model_vars，这个变量哪里被改变了？\n",
        "    return model_vars\n",
        "    \n",
        "  return _train_on_batch(model_vars, batch)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIoKDTSxZFP",
        "colab_type": "code",
        "outputId": "06251359-4414-4ab6-c37e-30299677eb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#输入<权重,偏移>model、<x,y>batch，输出权重和偏移也就是新模型，batch_train是在更新权重和偏移\n",
        "str(batch_train.type_signature)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>,float32> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGg9jVqmxb93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#最开始使用初始化模型，sample_batch的初始值为federated_train_data[5][-1]\n",
        "#将batch_train多次应用于初始模型，看损失是否减少\n",
        "model = initial_model\n",
        "loses = []\n",
        "for _ in range(5):\n",
        "  #batch_train更新权重和偏移，但是返回值model_vars没有看到在哪里被改变\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  loses.append(batch_loss(model, sample_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSkQCJTxfu8",
        "colab_type": "code",
        "outputId": "a1f52f2f-4eb9-4549-ea9c-09119c3b1e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loses"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19690023, 0.13176315, 0.10113225, 0.08273812, 0.07030139]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "freff1NExgWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构造一个序列化，则LOCAL_DATA_TYPE代表了一群BATCH_TYPE，来自一个用户的所有批的整个序列计算\n",
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "  #Mapping function to apply to each batch.\n",
        "  #定义batch_fn函数使用一个batch进行训练，更新模型参数\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "  #tff.sequence.reduce(value,zero,fn)在给定zero和操作fn的情况下对value进行操作以减少序列值\n",
        "  #tff.sequence.reduce和tf.data.Dataset.reduce作用差不多，只是前面一个用于联邦计算，联邦计算里面不能包含TensorFlow代码\n",
        "  #此处不停将batch_fn应用于all_batches中的每一个元素和initial然后将得到的结果赋值给initial_model？\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOS6tzRxiVV",
        "colab_type": "code",
        "outputId": "365f50ac-80ec-44fd-a8f7-a5208c902315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#local_train返回的是<权重,偏移>，则返回值是模型\n",
        "str(local_train.type_signature)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,float32,<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ilW11k4xkEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#federated_test_data[5]代表的是一个用户的所有batch，local_train计算了一个用户的所有batch\n",
        "locally_trained_model = local_train(initial_model, 0.1, federated_test_data[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8Wg7u_xmAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOCAL_DATA_TYPE代表一群batch，即每个用户的所有batch序列\n",
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  #TODO(b/120157713):Replace with tff.sequence_average() once implemented.\n",
        "  #tff.sequence.sum则计算loss的总和，这里是计算某个模型在特定数据集上面的表现\n",
        "  return tff.sequence_sum(\n",
        "      tff.sequence_map(\n",
        "          #lambda匿名函数:之前代表是匿名函数的参数\n",
        "          #将匿名函数应用到all_batches里面的每一个batch，然后会得到loss,all_batches是一个序列化的数\n",
        "          tff.federated_computation(lambda b: batch_loss(model, b),BATCH_TYPE),\n",
        "          all_batches\n",
        "      )\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILv4hi8Lxn9Q",
        "colab_type": "code",
        "outputId": "36c0b02c-9070-415c-b258-e990e74c4f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#signature表明，local_eval函数接收一个模型，一群batch作为输入最后返回一个32位浮点（损失）\n",
        "str(local_eval.type_signature)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>*> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZvDC9Ixpv6",
        "colab_type": "code",
        "outputId": "6f573d81-fced-457a-f659-2533d068603f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#初始模型\n",
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[5]))\n",
        "#进行了第五个用户所有batch训练之后的模型\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[5]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 0.57459134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdFW-VgXzjZz",
        "colab_type": "code",
        "outputId": "4813f397-ad23-4e19-ece6-5e5f70aad539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#查看该模型在其他数据集上面的表现，表明为用户5训练的locally_trained_model只会识别5，泛化能力差\n",
        "#问题：从全球的角度看，本地模型时如何影响模型质量\n",
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[0]))\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[0]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 72.66378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WSkaaSQ0HHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#定义服务器模型类型，MODEL_TYPE@SERVER\n",
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
        "#定义客户端数据类型，LOCAL_DATA_TYPE(一群batch)@CLIENTS\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9XhCnKJ0nj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#又定义federated_eval此时接收服务器的模型和客户端的batch\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE,CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  #federated_mean计算所有客户端的平均损失\n",
        "  return tff.federated_mean(\n",
        "      #tff.federated_broadcast将模型分发给客户机，让每个客户机对本地的数据调用本地计算，相当于{model_type@CLIENTS}\n",
        "      #有一个问题是怎么知道哪个客户机对应的data\n",
        "      #{model_type@CLIENTS，data_type@CLIENTS}和{<model，data>@CLIENTS}等价，前面那个会发生隐式转换，相当于调用了tff.federated_zip\n",
        "      #local_eval(model，all_batches)，federated_map将local_eval应用到每个客户端计算每个客户端的损失\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdjtsv_C1xxq",
        "colab_type": "code",
        "outputId": "6f4a7e75-79a7-4e7a-bfab-cc64eebe35c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model loss=', federated_eval(initial_model, federated_train_data))\n",
        "print('locally_trained_model, loss=', federated_eval(locally_trained_model, federated_train_data))\n",
        "#通过结果可以看出，损失增加，所以要改进每个用户的模型，需要对每个人的数据进行培训，因为前面只培训了一个用户？"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025852\n",
            "locally_trained_model, loss= 52.793297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8fMAKx2bgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#实现联合训练最简单的方法是本地训练然后对模型进行平均\n",
        "#构造一个SERVER_FLOAT_TYPE服务器数据类型，是一个放置在SERVER上的32位浮点\n",
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
        "#该函数接收三个参数，放置在SERVER上的模型和浮点数，放置在CLIENT上面的一群batch（分别是模型，浮点数，训练数据）\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  #前面已经说过，tff.federated_mean是计算model的联邦平均，最后求权重和偏移的平均？\n",
        "  return tff.federated_mean(\n",
        "      #此处相当于tff.federated_map(local_train，[{model,learning_rate,data}@CLIENTS])\n",
        "      #local_train是在给定的模型中以给定的学习率训练batch，然后返回一个model\n",
        "      tff.federated_map(local_train, [tff.federated_broadcast(model),tff.federated_broadcast(learning_rate),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lrjTBPM50ne",
        "colab_type": "code",
        "outputId": "79ae1289-eeff-494f-c9a1-70a4d9550ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#开始真正的fed训练：进行几轮训练并比较前后的平均损失\n",
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "for round_num in range(5):\n",
        "  #每一轮将大家的模型分别更新，取平均之后又拿回来，federated_train_data是MNIST数据集里面的训练数据\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  #更新学习率\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  #计算loss\n",
        "  loss = federated_eval(model, federated_train_data)\n",
        "  print('round{}, loss={}'.format(round_num, loss))\n",
        "  #下一轮统一的模型又还给各位CLIENTS去更新"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round0, loss=21.60552406311035\n",
            "round1, loss=20.365678787231445\n",
            "round2, loss=19.27480125427246\n",
            "round3, loss=18.31110954284668\n",
            "round4, loss=17.45725440979004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfoaHBsX9DRl",
        "colab_type": "code",
        "outputId": "097c6485-2b28-4697-89c1-59e48c2f3247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#在训练出来的模型上运行测试数据\n",
        "print('initial_model test loss=', federated_eval(initial_model, federated_test_data))\n",
        "print('trained_model test loss=', federated_eval(model, federated_test_data))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test loss= 22.795593\n",
            "trained_model test loss= 17.278767\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}