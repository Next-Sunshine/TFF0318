{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTFTest-Github-a2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMxFcoIK8EmeYzQudN0pYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TTF0318/blob/master/TTFTest_Github_a2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lanh716x5icx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruhN6Grz5q1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7cb40062-15a3-44e6-f4f2-62681df72255"
      },
      "source": [
        "#@test{\"skip\":true}\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 226kB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 39kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 33.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 60.8MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay5SMBO159CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install folium==0.2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_aaPZeF6ILS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "#TODO(b/148678573,b/148685415):must use the ReferenceExecutor because\n",
        "#it supports unbounded references and tff.sequence_* intrinsics\n",
        "tff.framework.set_default_executor(tff.framework.ReferenceExecutor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjn-ON9O6Q9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77567430-78fd-4f19-92cf-395b913b690b"
      },
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "hello_world()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnJ-nWUW6hmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f5062c1b-8c74-45e1-b7a8-663734009a25"
      },
      "source": [
        "#加载MNIST数据集\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVs6KddE6mrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4e37068-5f12-4c18-e5b4-ac9e91f5de31"
      },
      "source": [
        "#x.dtype应该是数据类型，uint8是8位无符号整型，x.shape是在打印x的维度\n",
        "[(x.dtype, x.shape) for x in mnist_train]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuKu9ko36o-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch翻译为批，CNN是分批处理，batch_size就是每批处理的大小\n",
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_data_for_digit(source,digit):\n",
        "  output_sequence = []\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i+ BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x':\n",
        "        np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                 dtype = np.float32),\n",
        "        'y':\n",
        "        np.array([source[1][i] for i in batch_samples], dtype= np.int32)\n",
        "    })\n",
        "  return output_sequence\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_VFc4s86wJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "14e59fbe-eea3-491c-9b2f-b8fb3f23c600"
      },
      "source": [
        "federated_train_data[5][-1]['y']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZWasANp6x93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "36f2a77b-5fc8-42f6-bd5a-6d0d37860727"
      },
      "source": [
        "#查看与该批次相对应的最后一个元素相对应的图像\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28,28), cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZaEZGfuiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkc0NIdg61Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb2aad86-f032-4c59-c7fe-44aebac7646a"
      },
      "source": [
        "BATCH_SPEC = collections.OrderedDict(\n",
        "    #维度设置为None表示大小未知\n",
        "    x = tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "    y = tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
        ")\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "str(BATCH_TYPE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<x=float32[?,784],y=int32[?]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p84sENHQ7EBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "374babe1-0752-427c-fc0b-7c5f9f273a92"
      },
      "source": [
        "MODEL_SPEC = collections.OrderedDict(\n",
        "    weights = tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
        "    bias = tf.TensorSpec(shape=[10], dtype=tf.float32)\n",
        ")\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights=float32[784,10],bias=float32[10]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtW2D6A67GZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: 'forward_pass' is defined separately from 'batch_loss'\n",
        "#so that it can be later called from within another tf.function.\n",
        "#Necessary because a @tf.function decorated method cannot\n",
        "# invoke a @tff.tf_computation.\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  predicted_y = tf.nn.softmax(\n",
        "      tf.matmul(batch['x'], model['weights']) + model['bias']\n",
        "  )\n",
        "  return -tf.reduce_mean(\n",
        "      tf.reduce_sum(\n",
        "      tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1])\n",
        "  )\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INA82A2D7NR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9066f77-0a6c-42d1-f3fb-222ebd1ada4d"
      },
      "source": [
        "str(batch_loss.type_signature)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65FNXL5o7PKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f832beb-fcc3-4cca-8667-8fdb2cd3237f"
      },
      "source": [
        "initial_model = collections.OrderedDict(\n",
        "    weights = np.zeros([784, 10], dtype=np.float32),\n",
        "    bias = np.zeros([10], dtype=np.float32)\n",
        ")\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1VxIxKz7S4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "51f4e84c-c752-4ef5-cc4c-d58307177e73"
      },
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  #Define a group of model variables and set them to 'initial_model'\n",
        "  #Must be defined outside the @tf.function.\n",
        "  model_vars = collections.OrderedDict([\n",
        "      (name, tf.Variable(name=name, initial_value=value))\n",
        "      for name, value in initial_model.items()                                  \n",
        "  ])\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from batch_loss\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
        "    return model_vars\n",
        "    \n",
        "  return _train_on_batch(model_vars, batch)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rHLPOZq7WOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b250d32-5fda-4beb-88e2-625d22c77fd0"
      },
      "source": [
        "str(batch_train.type_signature)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>,float32> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJSJ_QsL7ZKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = initial_model\n",
        "loses = []\n",
        "for _ in range(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  loses.append(batch_loss(model, sample_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}