{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTFTest-Github-a2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2WpjNZ6OYieHFj/cg0u9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TTF0318/blob/master/TTFTest_Github_a2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBPMpi1xw0zW",
        "colab_type": "code",
        "outputId": "70c33868-9fa3-460c-ea89-c138bca3c47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#@test{\"skip\":true}\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 39kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 242kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 61.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 52.0MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QyDgFLw-pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "#TODO(b/148678573,b/148685415):must use the ReferenceExecutor because\n",
        "#it supports unbounded references and tff.sequence_* intrinsics\n",
        "tff.framework.set_default_executor(tff.framework.ReferenceExecutor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRTbABCw_fn",
        "colab_type": "code",
        "outputId": "5c70168f-ea93-4bde-9541-8e061dc51db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "@tff.federated_computation\n",
        "def hello_world():\n",
        "  return 'Hello, World!'\n",
        "hello_world()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9FlqOxxBv9",
        "colab_type": "code",
        "outputId": "a331048d-8e98-43ef-c805-35866896de4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#加载MNIST数据集\n",
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_axy866xFst",
        "colab_type": "code",
        "outputId": "8ebbdf99-e6d0-4eb2-bb02-d79e3e374d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x.dtype应该是数据类型，uint8是8位无符号整型，x.shape是在打印x的维度\n",
        "[(x.dtype, x.shape) for x in mnist_train]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7P7TMLxGVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch翻译为批，CNN是分批处理，batch_size就是每批处理的大小\n",
        "#NUM_EXAMPLES_PER_USER是每个用户的样本数，每个用户有1000个样本，每次处理100个\n",
        "NUM_EXAMPLES_PER_USER = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_data_for_digit(source,digit):\n",
        "  output_sequence = []\n",
        "  #如果没有猜错，i代表的是客户端的序号，d代表的是数字\n",
        "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
        "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
        "    batch_samples = all_samples[i:i+ BATCH_SIZE]\n",
        "    output_sequence.append({\n",
        "        'x':\n",
        "        #flatten（）函数用于降维，返回一个一维数组，默认是按行的方向降维\n",
        "        np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
        "                 dtype = np.float32),\n",
        "        'y':\n",
        "        np.array([source[1][i] for i in batch_samples], dtype= np.int32)\n",
        "    })\n",
        "  return output_sequence\n",
        "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
        "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf5jsd3ZxKJG",
        "colab_type": "code",
        "outputId": "3eaa8cff-d23d-46b4-c9db-75431e5f2690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#查看第5个客户端提供的最后一批数据中的Y张量，输出结果有100个5，说明每个客户端100张图片\n",
        "#-1代表最后一列,好处是不知道一共有多少列也可以选定，一列是一批？\n",
        "federated_train_data[5][-1]['y']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJhzapqxK8J",
        "colab_type": "code",
        "outputId": "6d001348-e190-4938-cd37-289a735133ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#查看与该批次相对应的最后一个元素相对应的图像\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28,28), cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZaEZGfuiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrHhlkDxM9k",
        "colab_type": "code",
        "outputId": "d2e91718-e8e3-4861-a08f-932cc89eed48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#OrderedDict根据传入的顺序安排字典，而不是按照字母顺序安排字典\n",
        "BATCH_SPEC = collections.OrderedDict(\n",
        "    #维度设置为None表示大小未知,784列，数据类型为32位浮点\n",
        "    x = tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
        "    y = tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
        ")\n",
        "#to_type将指定类型转换成tff类型\n",
        "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
        "str(BATCH_TYPE)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<x=float32[?,784],y=int32[?]>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klk_oXp0xO7t",
        "colab_type": "code",
        "outputId": "5876b0f4-f449-401e-db82-086e1d572cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MODEL_SPEC = collections.OrderedDict(\n",
        "    weights = tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
        "    bias = tf.TensorSpec(shape=[10], dtype=tf.float32)\n",
        ")\n",
        "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
        "\n",
        "print(MODEL_TYPE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<weights=float32[784,10],bias=float32[10]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIb6UGiVxQ2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: 'forward_pass' is defined separately from 'batch_loss'\n",
        "#so that it can be later called from within another tf.function.\n",
        "#Necessary because a @tf.function decorated method cannot\n",
        "# invoke a @tff.tf_computation.\n",
        "#@tf.function将一个函数编译成一个可调用的TensorFlow图？示例代码说的是可以使函数中的类型\n",
        "#在对应位按照定义的函数操作且最后数据类型不变，数组对应位操作完了仍然是数组\n",
        "@tf.function\n",
        "def forward_pass(model, batch):\n",
        "  #tf.nn.softmax把一个N*1的向量归一化为（0,1）之间的特征值使得向量中数值较大的量特征更明显\n",
        "  #softmax输出向量的意思就是样本属于每个类的概率\n",
        "  predicted_y = tf.nn.softmax(\n",
        "      #batch为什么会有‘x'\n",
        "      #tf.matmul是线代矩阵相乘，应满足矩阵相乘条件且元素类型相同，返回一个新矩阵，tf.multiply则是矩阵的对应元素相乘\n",
        "      tf.matmul(batch['x'], model['weights']) + model['bias']\n",
        "  )\n",
        "  #reduce_mean(tensor,axis,Keepdim,name)降维计算数组的平均值,axis控制轴，没有则计算所有数的平均值返回一个数，\n",
        "  #0按列计算平均值，返回列个数，1按行计算平均值返回行个数\n",
        "  #其实应该是0代表第一个[[1,1,1],[1,1,1]]维度,即[1+1,1+1,1+1],1则第二个维度[1+1+1,1+1+1]\n",
        "  return -tf.reduce_mean(\n",
        "      #reduce_sum\n",
        "      tf.reduce_sum(\n",
        "      #构造一个独热码，batch['y']指示的地方是1，其他地方是0\n",
        "      tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1])\n",
        "  )\n",
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "def batch_loss(model, batch):\n",
        "  return forward_pass(model, batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2cD0ytyxS7u",
        "colab_type": "code",
        "outputId": "761a6e3e-bbe9-4c3a-ddee-603c4eb5d68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(batch_loss.type_signature)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-2K8j3xVTp",
        "colab_type": "code",
        "outputId": "97237549-ed97-4729-a907-4599fca3215e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "initial_model = collections.OrderedDict(\n",
        "    weights = np.zeros([784, 10], dtype=np.float32),\n",
        "    bias = np.zeros([10], dtype=np.float32)\n",
        ")\n",
        "sample_batch = federated_train_data[5][-1]\n",
        "batch_loss(initial_model, sample_batch)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3025854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UufkeLuoxXCa",
        "colab_type": "code",
        "outputId": "dfbf8a70-c529-4352-d151-0d37990422d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
        "def batch_train(initial_model, batch, learning_rate):\n",
        "  #Define a group of model variables and set them to 'initial_model'\n",
        "  #Must be defined outside the @tf.function.\n",
        "  model_vars = collections.OrderedDict([\n",
        "      (name, tf.Variable(name=name, initial_value=value))\n",
        "      for name, value in initial_model.items()                                  \n",
        "  ])\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def _train_on_batch(model_vars, batch):\n",
        "    # Perform one step of gradient descent using loss from batch_loss\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = forward_pass(model_vars, batch)\n",
        "    grads = tape.gradient(loss, model_vars)\n",
        "    optimizer.apply_gradients(\n",
        "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
        "    return model_vars\n",
        "    \n",
        "  return _train_on_batch(model_vars, batch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIoKDTSxZFP",
        "colab_type": "code",
        "outputId": "02eec9ac-b88e-4992-ee19-a7b43acf41c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(batch_train.type_signature)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>,float32> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGg9jVqmxb93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = initial_model\n",
        "loses = []\n",
        "for _ in range(5):\n",
        "  model = batch_train(model, sample_batch, 0.1)\n",
        "  loses.append(batch_loss(model, sample_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSkQCJTxfu8",
        "colab_type": "code",
        "outputId": "e9eb6043-bd1a-411c-cdab-df9fe5491744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loses"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19690023, 0.13176315, 0.10113225, 0.08273812, 0.07030139]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "freff1NExgWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构造一个序列化，则LOCAL_DATA_TYPE代表了一群BATCH_TYPE\n",
        "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
        "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
        "def local_train(initial_model, learning_rate, all_batches):\n",
        "  #Mapping function to apply to each batch.\n",
        "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
        "  def batch_fn(model, batch):\n",
        "    return batch_train(model, batch, learning_rate)\n",
        "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOS6tzRxiVV",
        "colab_type": "code",
        "outputId": "30cf4f4d-49fe-435d-f831-9e562d485820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(local_train.type_signature)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,float32,<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ilW11k4xkEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locally_trained_model = local_train(initial_model, 0.1, federated_test_data[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8Wg7u_xmAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
        "def local_eval(model, all_batches):\n",
        "  #TODO(b/120157713):Replace with tff.sequence_average() once implemented.\n",
        "  return tff.sequence_sum(\n",
        "      tff.sequence_map(\n",
        "          tff.federated_computation(lambda b: batch_loss(model, b),BATCH_TYPE),\n",
        "          all_batches\n",
        "      )\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILv4hi8Lxn9Q",
        "colab_type": "code",
        "outputId": "aa3a7011-643d-461d-e86d-d26251b3b24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(local_eval.type_signature)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>*> -> float32)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZvDC9Ixpv6",
        "colab_type": "code",
        "outputId": "1ee31d92-5cf8-4137-8392-d521eb494890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[5]))\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[5]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 0.57459134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdFW-VgXzjZz",
        "colab_type": "code",
        "outputId": "482b5d16-15f3-4c70-a3eb-c95628a4f7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model loss=', local_eval(initial_model, federated_train_data[0]))\n",
        "print('locally_trained_model loss=', local_eval(locally_trained_model, federated_train_data[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025854\n",
            "locally_trained_model loss= 72.66378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WSkaaSQ0HHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
        "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9XhCnKJ0nj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tff.federated_computation(SERVER_MODEL_TYPE,CLIENT_DATA_TYPE)\n",
        "def federated_eval(model, data):\n",
        "  return tff.federated_mean(\n",
        "      tff.federated_map(local_eval, [tff.federated_broadcast(model),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdjtsv_C1xxq",
        "colab_type": "code",
        "outputId": "36c68858-2e02-4121-ef95-0e2ea22846df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model loss=', federated_eval(initial_model, federated_train_data))\n",
        "print('locally_trained_model, loss=', federated_eval(locally_trained_model, federated_train_data))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model loss= 23.025852\n",
            "locally_trained_model, loss= 52.793297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8fMAKx2bgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
        "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
        "def federated_train(model, learning_rate, data):\n",
        "  return tff.federated_mean(\n",
        "      tff.federated_map(local_train, [tff.federated_broadcast(model),tff.federated_broadcast(learning_rate),data])\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lrjTBPM50ne",
        "colab_type": "code",
        "outputId": "bbf712a6-4ccf-4100-ea0a-799e86554bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#开始真正的fed训练\n",
        "model = initial_model\n",
        "learning_rate = 0.1\n",
        "for round_num in range(5):\n",
        "  #每一轮将大家的模型分别更新，取平均之后又拿回来\n",
        "  model = federated_train(model, learning_rate, federated_train_data)\n",
        "  #更新学习率\n",
        "  learning_rate = learning_rate * 0.9\n",
        "  #计算loss\n",
        "  loss = federated_eval(model, federated_train_data)\n",
        "  print('round{}, loss={}'.format(round_num, loss))\n",
        "  #下一轮统一的模型又还给各位CLIENTS去更新"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round0, loss=21.60552406311035\n",
            "round1, loss=20.365678787231445\n",
            "round2, loss=19.27480125427246\n",
            "round3, loss=18.31110954284668\n",
            "round4, loss=17.45725440979004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfoaHBsX9DRl",
        "colab_type": "code",
        "outputId": "064c1add-cb34-4071-840a-a7d27a0f4c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('initial_model test loss=', federated_eval(initial_model, federated_test_data))\n",
        "print('trained_model test loss=', federated_eval(model, federated_test_data))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial_model test loss= 22.795593\n",
            "trained_model test loss= 17.278767\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}