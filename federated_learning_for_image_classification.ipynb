{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "federated_learning_for_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI4PT3mQUOgXkyQJhTwKYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Next-Sunshine/TTF0318/blob/master/federated_learning_for_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVsSnETYUw1q",
        "colab_type": "code",
        "outputId": "5417381a-aa7f-4de0-c810-d4c4a0ffae4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "#@test {\"skip:true\"}\n",
        "!pip install --quiet --upgrade tensorflow_federated"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 430kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.0MB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 49.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 37.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 35kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 52.7MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ7YtpDWWIc3",
        "colab_type": "code",
        "outputId": "43679186-dc08-417a-ef85-875c51e7363f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello,world!')()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello,world!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZw9atJyrMm",
        "colab_type": "code",
        "outputId": "a94ef825-6278-4e59-f0ca-cad79daa65c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#装载数据集，EMNIST数据集\n",
        "#load_data()返回的数据集是tff.simulation.ClientData的实例\n",
        "#tff.simulation.clientData.create_tf_dataset_for_client返回的tf.data.dataset将在每次迭代中生成collections.OrderedDict对象，并具有以下键和值：\n",
        "#‘pixels':dtype=tf.float32且shape为[28，28]的tf.Tensor，包含手写数字的像素，其值在[0.0，1.0]范围内\n",
        "#‘label'：dtype=tf.int32且形状为[1]的tf.Tensor，是相应像素的类标签\n",
        "#标签[0-9]对应于数字类，标签[10-35]对应于大写类（例如，标签11是“B”），标签[36-61]对应于小写类（例如，标签37是“b”）。\n",
        "#pixels是图片的key，label是对应图片标签的key\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist_digitsonly.tar.bz2\n",
            "97402880/97398400 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FtPEuwz_DP",
        "colab_type": "code",
        "outputId": "d319a2ff-55b2-44bf-f7d0-b0bdbff63913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#存放着用户id的数组？\n",
        "len(emnist_train.client_ids) #输出3383\n",
        "len(emnist_test.client_ids) #输出3383"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S_AFeKkzOhH",
        "colab_type": "code",
        "outputId": "a8a46b23-014b-4dd8-b901-0d31e7fdf4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#element_type_structure查看类型结构？\n",
        "emnist_train.element_type_structure"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
              "             ('pixels',\n",
              "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IA21EVxzaxy",
        "colab_type": "code",
        "outputId": "231d8b0a-ced6-45ed-ab83-9a28026fb635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#create_tf_dataset_for_client接收用户client_id作为参数，返回创造的数据集\n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0]\n",
        ")\n",
        "#在一个博客上看到了另外一种写法：example_element = iter(example_dataset).next()\n",
        "#iter(example_dataset)获取数据集的迭代器，那么next（iter（example_dataset））就是该数据集的第一个元素\n",
        "example_element = next(iter(example_dataset))\n",
        "example_element['label'].numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYuWslDyrSrN",
        "colab_type": "code",
        "outputId": "abc95a8f-f24d-4712-8856-9ec33745da62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#这个打印出来是一群数[0,1]，还有换行符\n",
        "str(example_element['pixels'].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[[1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         0.99607843\\n  0.99215686 0.99607843 1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         0.9882353  0.9882353  1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         0.99215686 1.         1.         1.         1.\\n  0.8117647  0.91764706 1.         0.99607843 1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  0.9882353  1.         1.         0.7176471  0.3137255  0.14117648\\n  0.02352941 0.47058824 1.         0.9882353  1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         0.9882353\\n  1.         0.7647059  0.16078432 0.11372549 0.33333334 0.5803922\\n  0.88235295 0.98039216 0.99607843 1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         0.99607843 1.         1.\\n  0.6901961  0.2627451  0.64705884 0.9764706  1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         0.99607843 0.98039216 0.99607843 0.38039216\\n  0.29803923 1.         1.         1.         0.9843137  0.9882353\\n  0.99215686 1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         0.18431373\\n  0.25882354 0.92941177 0.98039216 0.99215686 1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  0.99607843 0.99607843 0.9137255  0.5019608  0.92156863 1.\\n  0.08627451 0.3882353  1.         0.9843137  1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  0.9882353  1.         0.42745098 0.01176471 0.5529412  0.56078434\\n  0.05882353 0.7294118  0.99607843 0.9882353  1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  0.99607843 1.         0.92156863 0.48235294 0.23529412 0.23529412\\n  0.6901961  1.         0.99607843 1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         0.99607843 1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         0.99607843 0.9843137  0.9882353  0.9882353\\n  0.9882353  1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]\\n [1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.         1.         1.\\n  1.         1.         1.         1.        ]]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouhoDglF0qQt",
        "colab_type": "code",
        "outputId": "8c829a37-736f-4cf2-a228-47af6aa8de07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#imshow(X,cmap)X可以是数列类格式、或者PIL图片,cmap是colormap，aspect有None，equal，auto（该表图片横纵比以适应坐标轴），scalar\n",
        "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
        "plt.grid(False)\n",
        "#这里这个画应该是一种很随意的，因为不想再用所以命名就是_\n",
        "#plt.imshow（）负责对图像进行处理并调整其格式但是不能显示，必须在其后跟着plt.show()才能成功显示出来\n",
        "_=plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZoCkWHv1ad7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "NUM_CLIENTS = 10  #用户数量\n",
        "#一个epoch指代所有的数据送入网络中完成一次前向计算及反向传播的过程\n",
        "#epoch可理解为轮数嘛？数据多样化越强epoch应该越大，一个epoch就是把整个训练集过一遍\n",
        "#iterations就是完成一次epoch所需的batch个数\n",
        "NUM_EPOCHS = 5  #轮数\n",
        "BATCH_SIZE = 20  #批大小\n",
        "#shuffle_buffer会影响转换的随机性？\n",
        "SHUFFLE_BUFFER = 100  #洗牌缓冲区是什么？？？\n",
        "#添加预取缓冲区可以通过将数据的预处理与下游计算重叠来提高性能。\n",
        "PREFETCH_BUFFER = 10   #预取缓冲区\n",
        "\n",
        "#由于数据已经是tf.data.Dataset因此可以使用数据集转换来完成预处理。\n",
        "#在这里我们将28×28图像展平成784个元素数组，对单个示例进行无序排列，将它们组织成批\n",
        "#将特征从pixels和label重命名为x和y以便于Keras一起使用，还对数据集进行一次重复，以运行多个时间段\n",
        "def preprocess(dataset):\n",
        "  #batch_format_fn将像素和标签转换成x和y\n",
        "  def batch_format_fn(element):\n",
        "    #Flatten a batch 'pixels' and return the features as an 'OrderedDict'\n",
        "    return collections.OrderedDict(\n",
        "        #-1理解为一个正整数通配符，它代替任何整数，所以reshape只指定了x的列数，将pixels弄成784列\n",
        "        x = tf.reshape(element['pixels'], [-1,784]),\n",
        "        #将label处理成一列，多少行无关\n",
        "        y = tf.reshape(element['label'], [-1,1])\n",
        "    )\n",
        "  #dataset.repeat(epoch_size)就是epoch，进行多遍训练\n",
        "  #dataset.shuffle(shuffle_size)就是将数据打乱，数值越大，混乱程度越大\n",
        "  #dataset.batch(batch_size)按照顺序取数据，每次取batch_size大小的数据\n",
        "  #dataset.map应该就是将map里面的fn应用到dataset里面的每一个元素吧\n",
        "  #dataset.prefetch（m）转换预取其直接输入的m个元素。在这种情况下，由于dataset.batch(n).prefetch(m)的直接输入是dataset.batch（n），并且该数据集的每个元素都是一个批（n个元素），所以它将预取m个批。\n",
        "  #prefetch可以保证下一个batch的数据对于 GPU 可以立即可用，减少 GPU 的数据等待时间.\n",
        "  #其中，m是预先被拉取数据的batches数.一般情况下，m=1.如果处理每个batch的耗时不同时，可以增加其值.\n",
        "  #官方说dataset.repeat放在shuffle之前可以提高性能\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwUWXjks2qsz",
        "colab_type": "code",
        "outputId": "d05ed9d9-4c24-423f-d078-aba23b57373a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "#对示例数据集进行预处理\n",
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "#预处理之后x代表图片array，y代表每一行的标签\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x', array([[1., 1., 1., ..., 1., 1., 1.],\n",
              "                     [1., 1., 1., ..., 1., 1., 1.],\n",
              "                     [1., 1., 1., ..., 1., 1., 1.],\n",
              "                     ...,\n",
              "                     [1., 1., 1., ..., 1., 1., 1.],\n",
              "                     [1., 1., 1., ..., 1., 1., 1.],\n",
              "                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n",
              "             ('y', array([[8],\n",
              "                     [8],\n",
              "                     [5],\n",
              "                     [3],\n",
              "                     [3],\n",
              "                     [4],\n",
              "                     [6],\n",
              "                     [7],\n",
              "                     [3],\n",
              "                     [9],\n",
              "                     [3],\n",
              "                     [2],\n",
              "                     [8],\n",
              "                     [7],\n",
              "                     [1],\n",
              "                     [3],\n",
              "                     [2],\n",
              "                     [4],\n",
              "                     [3],\n",
              "                     [3]], dtype=int32))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06iskEm3h5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#这里的client_data应该说的是mnist_train这一类的，通过load()加载来的\n",
        "#make_federated_data(client_data,client_ids)是在为每一个用户id创建联邦数据\n",
        "#从给定的用户集构造一个数据集列表，作为一轮培训或评估的输入。\n",
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "    #tff.simulation.clientData.create_tf_dataset_for_client返回的tf.data.dataset将在每次迭代中生成collections.OrderedDict对象，并具有以下键和值：\n",
        "    #‘pixels':dtype=tf.float32且shape为[28，28]的tf.Tensor，包含手写数字的像素，其值在[0.0，1.0]范围内\n",
        "    #‘label'：dtype=tf.int32且形状为[1]的tf.Tensor，是相应像素的类标签\n",
        "    #create_tf_dataset_for_client接收用户client_id作为参数，返回创造的数据集\n",
        "    preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "    for x in client_ids\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLCixM-4Qqr",
        "colab_type": "code",
        "outputId": "49cf37f2-8592-43be-f75f-20d651f27f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#sample_clients是在获得给定用户数量的用户id\n",
        "#！！！改动在这里，应该模拟随机采样，用户是随机的\n",
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of client datasets: 10\n",
            "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENelOjuG7Xeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keras模型\n",
        "def create_keras_model():\n",
        "  #另外，model.Sequential其他用法：建立一个最终输出维度为10的分类结果的全连接神经网络。使用.add()函数进行各个层的堆叠\n",
        "  #model = keras.Sequential() model.add(keras.layers.Dense(64, activation='relu')) model.add(keras.layers.Dense(64, activation='relu'))\n",
        "  #model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "  #或者通过将层的列表传递给Sequential的构造函数，来创建一个Sequential模型，返回一个tf.keras.model对象\n",
        "  return tf.keras.models.Sequential([\n",
        "    #shape=(784,)代表一个有784个元素的一维数组，例如[2,2]的形状是(2,)而[[2],[2]]的形状是(2,1)\n",
        "    tf.keras.layers.Input(shape = (784,)),\n",
        "    tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "    tf.keras.layers.Softmax(),\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciS80YJjYSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#为了将任何模型与TFF一起使用，需要将其包装在TFF.learning.model接口的实例中，该接口公开了用于标记模型的前向传递、元数据属性等的方法\n",
        "#类似于Keras，但还引入了其他元素，例如控制计算联合度量的过程的方法。scop:范围\n",
        "def model_fn():\n",
        "  # We _must_create a new model here, and not capture it from an external\n",
        "  #scop. TFF will call this within different graph contexts.\n",
        "  #from_keras_model(keras_model,loss,input_spec=None,loss_weights=None,metrics=None,dummy_batch=None)\n",
        "  #-keras_model:未编译的tf.keras.Model对象\n",
        "  #-loss:具有两个成批张量参数y_true和y_pred的可调用对象，并返回损失。如果模型具有多个输出，则可以通过传递字典或损失列表来在每个输出上使用不同的损失。然后，将由模型最小化的损失值将是所有单个损失的总和，每个损失都由loss_weights加权。\n",
        "  #-input_spec:（可选）可转换为tff.Type的值，指定模型期望的参数类型。请注意，这必须是两个元素的复合结构，同时将输入模型以生成预测的数据指定为第一个元素，并将预期的地面事实类型作为第二个元素。当我们删除dummy_batch时，将需要此参数；当前，必须精确指定这两个之一。\n",
        "  #-loss_weight:（可选）指定标量系数（Python浮点数）以加权不同模型输出的损耗贡献的列表或字典。 然后，将由模型最小化的损失值将是所有单个损失的加权总和，并由loss_weights系数加权。 如果是列表，则期望与模型的输出具有1：1映射。 如果是张量，则期望将输出名称（字符串）映射到标量系数。\n",
        "  #-metrics:（可选）tf.keras.metrics.Metric对象的列表。\n",
        "  #-dummy_batch:dummy_batch ：（可选，不建议使用）嵌套的值结构，可以将其转换为成批张量，其形状和类型与输入keras_model的形状和类型相同。张量的值并不重要，可以用任何合理的输入值填充。\n",
        "  keras_model = create_keras_model()\n",
        "  #返回一个给定的tff模型\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      #批样本？\n",
        "      dummy_batch=sample_batch,\n",
        "      #tf.keras.losses.SparseCategoricalCrossentropy()计算标签和预测之间的交叉熵损失。标签是以整数的形式提供而不是独热码\n",
        "      #独热码是CategoricalCrossentropy\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      #该评估器能够对模型预测的结果与真实结果进行比较，并输出预测正确的样本数占总样本数的比例。\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ydv1mBIlHC3",
        "colab_type": "code",
        "outputId": "89b5afc2-165d-457e-cb97-5a1c7c5824d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#有了一个包装为tf.learning.model的模型，可以调用tff.learning.build_federated_averaging_process构造联邦平均算法\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    #model_fn是构造函数，而不是构建好的实例\n",
        "    model_fn,\n",
        "    #客户端的优化器，这里以后可以照抄\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    #服务器的优化器函数\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzAmqg4wloGT",
        "colab_type": "code",
        "outputId": "f6b49fef-7bae-4d2c-ecbd-7123749bdf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "str(iterative_process.initialize.type_signature)\n",
        "#服务器状态由一个模型（将分发给所有设备的MNIST的初始模型参数）和优化器状态（服务器维护的附加信息，例如用于超参数计划的轮次数等）组成"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'( -> <model=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZjPYqhm6C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#调用初始化计算来构造服务器状态\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYIGJeKdnizT",
        "colab_type": "code",
        "outputId": "bf21d67e-d640-4282-b8be-f4a866620612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#next的签名：SERVER_STATE,FEDERATED_DATA->SERVER_STATE,TRAINING_METRICS\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round 1, metrics={}'.format(metrics))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 1, metrics=<sparse_categorical_accuracy=0.11954732239246368,loss=3.1037683486938477,keras_training_time_client_sum_sec=0.0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0jrjMVSn9Hk",
        "colab_type": "code",
        "outputId": "0d081d65-16ae-4d40-c6be-d3c522ad9b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#每轮联合训练后，训练损失都在减少，说明模型正在收敛。\n",
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2,NUM_ROUNDS):\n",
        "  state,metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round{:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 2, metrics=<sparse_categorical_accuracy=0.14094650745391846,loss=2.9814815521240234,keras_training_time_client_sum_sec=0.0>\n",
            "round 3, metrics=<sparse_categorical_accuracy=0.14835390448570251,loss=2.850893497467041,keras_training_time_client_sum_sec=0.0>\n",
            "round 4, metrics=<sparse_categorical_accuracy=0.18086419999599457,loss=2.640409469604492,keras_training_time_client_sum_sec=0.0>\n",
            "round 5, metrics=<sparse_categorical_accuracy=0.20061728358268738,loss=2.4948813915252686,keras_training_time_client_sum_sec=0.0>\n",
            "round 6, metrics=<sparse_categorical_accuracy=0.2146090567111969,loss=2.4961931705474854,keras_training_time_client_sum_sec=0.0>\n",
            "round 7, metrics=<sparse_categorical_accuracy=0.25390946865081787,loss=2.262115240097046,keras_training_time_client_sum_sec=0.0>\n",
            "round 8, metrics=<sparse_categorical_accuracy=0.24320988357067108,loss=2.3826146125793457,keras_training_time_client_sum_sec=0.0>\n",
            "round 9, metrics=<sparse_categorical_accuracy=0.3047325015068054,loss=2.0886857509613037,keras_training_time_client_sum_sec=0.0>\n",
            "round10, metrics=<sparse_categorical_accuracy=0.3123456835746765,loss=2.123420000076294,keras_training_time_client_sum_sec=0.0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPOyo4IsvFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#使用Tensorboard可视化这些联邦计算的度量\n",
        "#创建目录和相应的摘要编写器\n",
        "#@test {\"skip\": true}\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqTNLcAyVc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!!太坑了，我以为@test是无关紧要的东西，emmm，就省略了，没想到就凉凉\n",
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics._asdict().items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlkcZCcycoG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kill 641"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Q_zvOrzHpB",
        "colab_type": "code",
        "outputId": "1dcc0412-085e-41d4-8200-da47a0a35984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "#@test {\"skip\":true}\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKiAJ8_OOr37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@test {\"skip\":true}\n",
        "#Run this cell to clean your directory of old output for future graphs from this drrectory.\n",
        "!rm -R /tmp/logs/scalars/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A44-oLfzQvDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#namedtuple（）返回具有命名字段的元组的新子类，将weights等作为MnistVariables的属性包装在MnistVariables中\n",
        "#定义一个数据结构来表示整个集合。这将包括变量，如我们将要训练的权重和偏差，以及变量，\n",
        "#这些变量将保存我们在训练期间更新的各种累积统计和计数器，loss_sum, accuracy_sum, 和 num_examples.。\n",
        "#定义了一个变量集合来表示所有变量\n",
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables','weights bias num_examples loss_sum accuracy_sum'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQV8RndmRHmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#创建变量的方法\n",
        "#将所有统计数据表示为tf.float32，因为这将在稍后阶段消除类型转换的需要。将变量初始值设定项包装为lambdas是资源变量强加的要求。\n",
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      #tf.Variables()定义一个变量，一般会把权重这些这样定义\n",
        "      #tf.placeholder()或者tf.TensorSpec()则定义一个固定类型的张量，一般输入输出会这样定义\n",
        "      weights=tf.Variable(\n",
        "          #定义形状以及初始化，权重将784维的向量变成10维的\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),\n",
        "          name='weights',\n",
        "          trainable=True),\n",
        "      bias=tf.Variable(\n",
        "          #偏移的形状是有10个元素的1维向量\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
        "          name='bias',\n",
        "          trainable=True),\n",
        "      #样本数：不可训练，同理损失和以及精度和也是，这些数都将初始化为0\n",
        "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqDtVPiZFSd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mnist_forward_pass(variables, batch):\n",
        "  #softmax()输出样本属于各个类别的概率\n",
        "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
        "  #tf.argmax(y,1)将y中的最大值！！下标！！取出来\n",
        "  #tf.cast()则将tf.argmax(y,1)得到的类型转换成tf.int32类型的\n",
        "  predictions = tf.cast(tf.argmax(y,1), tf.int32)\n",
        "\n",
        "  #将batch['y']也就是label转变成1维数组\n",
        "  flat_labels = tf.reshape(batch['y'], [-1])\n",
        "  #计算交叉熵损失\n",
        "  loss = -tf.reduce_mean(\n",
        "      tf.reduce_sum(tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))\n",
        "  #计算准确率，即将预测值和label进行对比，得到True和False的数组，然后将bool类型转换成32位浮点，然后再求平均值，也就是在计算精度\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
        "\n",
        "  #样本数=label的数量然后转变成32位浮点？\n",
        "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
        "\n",
        "  #更新样本数，变量里面的样本数+=本批样本数\n",
        "  variables.num_examples.assign_add(num_examples)\n",
        "  #更新损失和，损失和+=损失×本批样本数   自动带上了本地的样本权重？这是什么意思，仔细看了一下后面的损失，还真的大于了1\n",
        "  variables.loss_sum.assign_add(loss * num_examples)\n",
        "  #更新精度和，精度和+=精度×本批样本数\n",
        "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r2MLFpJJcIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#计算本地用户度量，metrics 度量\n",
        "#input_metrics参数对应于上面get_local_mnist_metrics返回的OrderedDict\n",
        "def get_local_mnist_metrics(variables):\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=variables.num_examples,\n",
        "      loss=variables.loss_sum / variables.num_examples,\n",
        "      accuracy=variables.accuracy_sum / variables.num_examples\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH6-avamJ6z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#聚合每个设备发出的本地度量\n",
        "@tff.federated_computation\n",
        "def aggregate_mnist_metrics_across_clients(metrics):\n",
        "  return collections.OrderedDict(\n",
        "    num_examples=tff.federated_sum(metrics.num_examples),\n",
        "    #使用loss和/num_examples来计算平均损失\n",
        "    loss=tff.federated_mean(metrics.loss, metrics.num_examples),\n",
        "    accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC6NrM3iKhtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构建tff.learning.model实例\n",
        "class MnistModel(tff.learning.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  #property代表属性，可训练变量即权重和偏移（权重和偏移是model的属性）\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    return [self._variables.weights, self._variables.bias]\n",
        "\n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "\n",
        "  #本地变量，权重和偏移是model的变量存在SERVER所以本地变量应该就是剩下那几个\n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [\n",
        "      self._variables.num_examples, self._variables.loss_sum,\n",
        "      self._variables.accuracy_sum\n",
        "    ]\n",
        "\n",
        "  #模型应该描述它接受什么形式的数据（input_spec）\n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict(\n",
        "      #TensorSpec和占位符一样，一般用来表示输入输出这种\n",
        "      x=tf.TensorSpec([None, 784], tf.float32),\n",
        "      y=tf.TensorSpec([None, 1], tf.int32))\n",
        "  \n",
        "  #@tf.function将python代码转换成图保存\n",
        "  @tf.function\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    #del删除training变量？\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    num_examples = tf.shape(batch['x'])[0]\n",
        "    return tff.learning.BatchOutput(\n",
        "        loss=loss, predictions=predictions, num_examples=num_examples)\n",
        "  \n",
        "  #报告本地输出\n",
        "  @tf.function\n",
        "  def report_local_outputs(self):\n",
        "    return get_local_mnist_metrics(self._variables)\n",
        "\n",
        "  #联邦输出计算，报告聚合了本地计算的联邦结果\n",
        "  @property\n",
        "  def federated_output_computation(self):\n",
        "    return aggregate_mnist_metrics_across_clients\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWRUpzdNNj9l",
        "colab_type": "code",
        "outputId": "e5aad30b-162b-4a47-8970-cc5f4ec283cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#对于联合平均，我们需要指定模型应该如何在每个批上进行本地训练。我们将在构建联邦平均算法时指定一个本地优化器。\n",
        "#用新模型模拟联合训练\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "  MnistModel,\n",
        "  client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7fa0faffd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function zero_all_if_any_non_finite at 0x7fa0faffd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7fa0faffd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function zero_all_if_any_non_finite at 0x7fa0faffd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7LG2uZEPz4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = iterative_process.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4E6SCI6P5gN",
        "colab_type": "code",
        "outputId": "16cac664-3cff-4239-86ae-6ab4995ba6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round 1, metrics={}'.format(metrics))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 1, metrics=<num_examples=4860.0,loss=3.078794240951538,accuracy=0.1286008208990097>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OhdVU0EQI7f",
        "colab_type": "code",
        "outputId": "e58d1ac8-e562-4997-9416-617dcd30e4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "for round_num in range(2,11):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n",
            "round  2, metrics=<num_examples=4860.0,loss=2.912949323654175,accuracy=0.1384773701429367>\n",
            "round  3, metrics=<num_examples=4860.0,loss=2.9531896114349365,accuracy=0.14897119998931885>\n",
            "round  4, metrics=<num_examples=4860.0,loss=2.7291486263275146,accuracy=0.1639917641878128>\n",
            "round  5, metrics=<num_examples=4860.0,loss=2.5692806243896484,accuracy=0.20843622088432312>\n",
            "round  6, metrics=<num_examples=4860.0,loss=2.474888324737549,accuracy=0.21975308656692505>\n",
            "round  7, metrics=<num_examples=4860.0,loss=2.3740530014038086,accuracy=0.2397119402885437>\n",
            "round  8, metrics=<num_examples=4860.0,loss=2.20986008644104,accuracy=0.26851850748062134>\n",
            "round  9, metrics=<num_examples=4860.0,loss=2.18491530418396,accuracy=0.2930041253566742>\n",
            "round 10, metrics=<num_examples=4860.0,loss=2.041264295578003,accuracy=0.32325103878974915>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qotjyjrlQtBQ",
        "colab_type": "code",
        "outputId": "110a4f8a-1fca-4496-e592-a02051952113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        }
      },
      "source": [
        "#使用tensorboard可视化\n",
        "#使用Tensorboard可视化这些联邦计算的度量\n",
        "#创建目录和相应的摘要编写器\n",
        "#@test {\"skip\": true}\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "#!!!太坑了，我以为@test是无关紧要的东西，emmm，就省略了，没想到就凉凉\n",
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics._asdict().items():\n",
        "      tf.summary.scalar(name, value, step=round_num)\n",
        "\n",
        "#@test {\"skip\":true}\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfEl0awRVIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@test {\"skip\":true}\n",
        "#Run this cell to clean your directory of old output for future graphs from this drrectory.\n",
        "!rm -R /tmp/logs/scalars/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xNf-dGMRh1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(MnistModel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUkh_EKaRq-F",
        "colab_type": "code",
        "outputId": "b5cded20-68e6-4c7b-e3d0-48727ae650d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "str(evaluation.type_signature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(<<trainable=<float32[784,10],float32[10]>,non_trainable=<>>@SERVER,{<x=float32[?,784],y=int32[?,1]>*}@CLIENTS> -> <num_examples=float32@SERVER,loss=float32@SERVER,accuracy=float32@SERVER>)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe2_36T-RvVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_metrics = evaluation(state.model, federated_train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvlVCc3R5At",
        "colab_type": "code",
        "outputId": "aa8125d0-ce42-4d10-de84-73355572d803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(train_metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<num_examples=4860.0,loss=1.523190975189209,accuracy=0.6388888955116272>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Hvy89zR769",
        "colab_type": "code",
        "outputId": "f65b6ee6-e7d9-4755-84f4-3c558c5b9137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
        "len(federated_test_data), federated_test_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,\n",
              " <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH4GJwA8SPiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_metrics = evaluation(state.model, federated_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpGOsV9VSWG7",
        "colab_type": "code",
        "outputId": "358d7265-2ab3-441e-d221-cd3c29fee522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(test_metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<num_examples=580.0,loss=1.6153969764709473,accuracy=0.6034482717514038>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}